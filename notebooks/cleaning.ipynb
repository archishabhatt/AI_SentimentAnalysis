{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b42bc736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import string\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48492d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be824e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA HARMONIZATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "Total comments: 3099\n",
      "Reddit comments: 1012\n",
      "YouTube comments: 2087\n",
      "\n",
      "Sentiment distribution:\n",
      "sentiment_label\n",
      "positive    2052\n",
      "negative     958\n",
      "neutral       89\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average VADER scores:\n",
      "  Compound: 0.260\n",
      "  Positive: 0.122\n",
      "  Negative: 0.072\n",
      "  Neutral: 0.806\n",
      "\n",
      "Date range:\n",
      "  Earliest: 2021-10-20 04:04:18+00:00\n",
      "  Latest: 2025-12-07 04:55:25+00:00\n",
      "\n",
      "Top communities:\n",
      "platform_community\n",
      "MachineLearning           406\n",
      "TED                       400\n",
      "LocalLLaMA                271\n",
      "CNN                       200\n",
      "ChatGPT                   169\n",
      "CNBC Television           116\n",
      "Senator Bernie Sanders    100\n",
      "Fireship                  100\n",
      "WIRED                     100\n",
      "The Diary Of A CEO        100\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Content flags:\n",
      "  Contains AI keywords: 3099\n",
      "  Contains opinion keywords: 2845\n",
      "  Contains societal keywords: 1230\n"
     ]
    }
   ],
   "source": [
    "def harmonize_reddit_data(df):\n",
    "    \"\"\"Standardize Reddit data to unified schema (VADER version)\"\"\"\n",
    "    \n",
    "    # Create unified schema\n",
    "    harmonized = pd.DataFrame()\n",
    "    \n",
    "    # Core text fields\n",
    "    harmonized['text'] = df['text']\n",
    "    harmonized['text_length'] = df['comment_length']\n",
    "    \n",
    "    # Sentiment - VADER scores\n",
    "    harmonized['sentiment_compound'] = df['sentiment_polarity']  # VADER compound score\n",
    "    harmonized['sentiment_positive'] = df['sentiment_positive']  # VADER positive score\n",
    "    harmonized['sentiment_negative'] = df['sentiment_negative']  # VADER negative score\n",
    "    harmonized['sentiment_neutral'] = df['sentiment_neutral']    # VADER neutral score\n",
    "    harmonized['sentiment_subjectivity'] = df['sentiment_subjectivity']\n",
    "    \n",
    "    # Sentiment label (updated threshold for VADER)\n",
    "    harmonized['sentiment_label'] = df.get('sentiment_label', \n",
    "                                            df['sentiment_polarity'].apply(\n",
    "                                                lambda x: 'positive' if x >= 0.05 else ('negative' if x <= -0.05 else 'neutral')))\n",
    "    \n",
    "    # Engagement metrics\n",
    "    harmonized['likes'] = df['likes']\n",
    "    harmonized['replies'] = df['num_replies']\n",
    "    \n",
    "    # Temporal\n",
    "    harmonized['created_at'] = pd.to_datetime(df['created_utc'], errors='coerce')\n",
    "    \n",
    "    # Source identification\n",
    "    harmonized['source'] = 'reddit'\n",
    "    harmonized['source_id'] = df['source_id']\n",
    "    \n",
    "    # Platform-specific metadata\n",
    "    harmonized['platform_post_id'] = df['post_id']\n",
    "    harmonized['platform_post_title'] = df['post_title']\n",
    "    harmonized['platform_community'] = df['subreddit']\n",
    "    harmonized['platform_post_score'] = df['post_score']\n",
    "    harmonized['platform_post_engagement'] = df['post_num_comments']\n",
    "    \n",
    "    # Content flags\n",
    "    harmonized['contains_ai'] = df['contains_ai']\n",
    "    harmonized['contains_opinion'] = df['contains_opinion']\n",
    "    harmonized['contains_societal'] = df['contains_societal']\n",
    "    \n",
    "    return harmonized\n",
    "\n",
    "def harmonize_youtube_data(df):\n",
    "    \"\"\"Standardize YouTube data to unified schema (VADER version)\"\"\"\n",
    "    \n",
    "    # Create unified schema\n",
    "    harmonized = pd.DataFrame()\n",
    "    \n",
    "    # Core text fields\n",
    "    harmonized['text'] = df['text']\n",
    "    harmonized['text_length'] = df['comment_length']\n",
    "    \n",
    "    # Sentiment - VADER scores\n",
    "    harmonized['sentiment_compound'] = df['sentiment_polarity']  # VADER compound score\n",
    "    harmonized['sentiment_positive'] = df['sentiment_positive']  # VADER positive score\n",
    "    harmonized['sentiment_negative'] = df['sentiment_negative']  # VADER negative score\n",
    "    harmonized['sentiment_neutral'] = df['sentiment_neutral']    # VADER neutral score\n",
    "    harmonized['sentiment_subjectivity'] = df['sentiment_subjectivity']\n",
    "    \n",
    "    # Sentiment label (updated threshold for VADER)\n",
    "    harmonized['sentiment_label'] = df.get('sentiment_label',\n",
    "                                            df['sentiment_polarity'].apply(\n",
    "                                                lambda x: 'positive' if x >= 0.05 else ('negative' if x <= -0.05 else 'neutral')))\n",
    "    \n",
    "    # Engagement metrics\n",
    "    harmonized['likes'] = df['likes']\n",
    "    harmonized['replies'] = df['num_replies']\n",
    "    \n",
    "    # Temporal\n",
    "    harmonized['created_at'] = pd.to_datetime(df['created_utc'], errors='coerce')\n",
    "    \n",
    "    # Source identification\n",
    "    harmonized['source'] = 'youtube'\n",
    "    harmonized['source_id'] = df['source_id']\n",
    "    \n",
    "    # Platform-specific metadata\n",
    "    harmonized['platform_post_id'] = df['video_id']\n",
    "    harmonized['platform_post_title'] = df['video_title']\n",
    "    harmonized['platform_community'] = df['video_channel']\n",
    "    harmonized['platform_post_score'] = df['video_like_count']\n",
    "    harmonized['platform_post_engagement'] = df['video_comment_count']\n",
    "    \n",
    "    # Content flags\n",
    "    harmonized['contains_ai'] = df['contains_ai']\n",
    "    harmonized['contains_opinion'] = df['contains_opinion']\n",
    "    harmonized['contains_societal'] = df['contains_societal']\n",
    "    \n",
    "    return harmonized\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the data\n",
    "    reddit_df = pd.read_csv('../data/reddit_ai.csv')\n",
    "    youtube_df = pd.read_csv('../data/youtube_ai.csv')\n",
    "    \n",
    "    # Harmonize datasets\n",
    "    reddit_harmonized = harmonize_reddit_data(reddit_df)\n",
    "    youtube_harmonized = harmonize_youtube_data(youtube_df)\n",
    "    \n",
    "    # Merge datasets\n",
    "    merged_df = pd.concat([reddit_harmonized, youtube_harmonized], ignore_index=True)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"=\"*60)\n",
    "    print(\"DATA HARMONIZATION COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nTotal comments: {len(merged_df)}\")\n",
    "    print(f\"Reddit comments: {len(reddit_harmonized)}\")\n",
    "    print(f\"YouTube comments: {len(youtube_harmonized)}\")\n",
    "    \n",
    "    print(f\"\\nSentiment distribution:\")\n",
    "    print(merged_df['sentiment_label'].value_counts())\n",
    "    \n",
    "    print(f\"\\nAverage VADER scores:\")\n",
    "    print(f\"  Compound: {merged_df['sentiment_compound'].mean():.3f}\")\n",
    "    print(f\"  Positive: {merged_df['sentiment_positive'].mean():.3f}\")\n",
    "    print(f\"  Negative: {merged_df['sentiment_negative'].mean():.3f}\")\n",
    "    print(f\"  Neutral: {merged_df['sentiment_neutral'].mean():.3f}\")\n",
    "    \n",
    "    print(f\"\\nDate range:\")\n",
    "    print(f\"  Earliest: {merged_df['created_at'].min()}\")\n",
    "    print(f\"  Latest: {merged_df['created_at'].max()}\")\n",
    "    \n",
    "    print(f\"\\nTop communities:\")\n",
    "    print(merged_df['platform_community'].value_counts().head(10))\n",
    "    \n",
    "    print(f\"\\nContent flags:\")\n",
    "    print(f\"  Contains AI keywords: {merged_df['contains_ai'].sum()}\")\n",
    "    print(f\"  Contains opinion keywords: {merged_df['contains_opinion'].sum()}\")\n",
    "    print(f\"  Contains societal keywords: {merged_df['contains_societal'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afff5e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text_length",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentiment_compound",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_positive",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_negative",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_neutral",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_subjectivity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "likes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "replies",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "created_at",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform_post_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform_post_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform_community",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform_post_score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_post_engagement",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "contains_ai",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "contains_opinion",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "contains_societal",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "3ce8e6c9-8d5c-4042-947d-c82d89b92e46",
       "rows": [
        [
         "0",
         "Post is definitely worded or written by an AI, but it's actually an interesting discussion topic. The most prominent figure that can't stop talking about world models is Yann Lecun, who links it to ideas in model predictive control. Current LLMs can approximate reasonings decently well, but it's still just an approximation. An actual world model would enable real reasoning and planning, which is where the hype comes from. Real planning through tree search with a world model is how we get actual superhuman-level AI that clearly demonstrates its creativity like AlphaGo and its successors. The reasoning traces of current LLMs feel too much like just following and replicating human's chain of thoughts. It's the best we've got in general-purpose reasoning now, but it's clearly limited.",
         "126",
         "0.989",
         "0.254",
         "0.015",
         "0.731",
         "0.8694999999999999",
         "positive",
         "1",
         "1",
         "2025-11-14 22:20:11+00:00",
         "reddit",
         "reddit_comment_novuyda",
         "1ox5xu0",
         "[D] Let's discuss World Models",
         "MachineLearning",
         "0",
         "6",
         "True",
         "True",
         "True"
        ],
        [
         "1",
         "Yes post is refined using LLM\n\nHowever following are sources from where my thoughts are derived:\n\n* [Do generative video models understand physical principles?](https://arxiv.org/pdf/2501.09038) \\- It has good overview of how current video generation models understand physics principles and it introduces a benchmark as well **Physics-IQ**.\n* [Awesome-World-Model](https://github.com/nik-55/world-models): List of research works and projects on world models\n* Yesterday deepmind release the [sima 2](https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/) and in past month, It had released [Genie 3](https://deepmind.google/blog/genie-3-a-new-frontier-for-world-models/)\n* Nvidia [Cosmos](https://www.nvidia.com/en-in/ai/cosmos/) and [Omniverse platform](https://www.nvidia.com/en-in/omniverse/) - Jensen mentioned in number of interviews about world foundation models\n* Worldlabs.ai release [interactive world model](https://www.worldlabs.ai/blog/marble-world-model) few days back\n\nSo As I read them I am curios to know what's the community take on it. This community seems to be nice place to get to know thoughts and their perspectives on this topic",
         "133",
         "0.8689",
         "0.084",
         "0.0",
         "0.916",
         "0.55945",
         "positive",
         "-6",
         "1",
         "2025-11-14 20:17:37+00:00",
         "reddit",
         "reddit_comment_nov7r5c",
         "1ox5xu0",
         "[D] Let's discuss World Models",
         "MachineLearning",
         "0",
         "6",
         "True",
         "True",
         "False"
        ],
        [
         "2",
         "I mean, asking the people that have a culturual vibe that created the literal term \"german angst\" about something new and potentially scary and then getting the answer \"they are scared\" seems pretty on the nose...  \nOnly asking people from one country feels like a fairly biased sample.",
         "48",
         "-0.128",
         "0.133",
         "0.142",
         "0.725",
         "0.064",
         "negative",
         "2",
         "1",
         "2025-08-21 08:48:54+00:00",
         "reddit",
         "reddit_comment_n9v0fig",
         "1mvmlbw",
         "[R] What do people expect from AI in the next decade across various domains? Survey with N=1100 people from Germay::We found high likelihood, higher perceived risks, yet limited benefits low perceived value. Yet, benefits outweight risks in forming value judgments. Visual result illustrations :)",
         "MachineLearning",
         "9",
         "8",
         "True",
         "True",
         "True"
        ],
        [
         "3",
         "Interesting, for me it opens a page for the paper ‘Mapping public perception of artificial intelligence: Expectations, risk–benefit tradeoffs, and value as determinants for societal acceptance’, this without any account in Germany",
         "32",
         "0.802",
         "0.22",
         "0.0",
         "0.78",
         "0.401",
         "positive",
         "1",
         "0",
         "2025-08-20 19:06:03+00:00",
         "reddit",
         "reddit_comment_n9rgz0a",
         "1mvmlbw",
         "[R] What do people expect from AI in the next decade across various domains? Survey with N=1100 people from Germay::We found high likelihood, higher perceived risks, yet limited benefits low perceived value. Yet, benefits outweight risks in forming value judgments. Visual result illustrations :)",
         "MachineLearning",
         "9",
         "8",
         "True",
         "True",
         "True"
        ],
        [
         "4",
         "I've seen an increasing rise in physics and engineering cranks who are convinced they've got a theory of quantum gravity/perpetual energy/etc that they've \"validated\" by working with chatgpt. Many of them are software devs who've drank the Twitter koolaid very hard. \n\nLLMs are an unfortunately good way to validate delusions of people who are generally otherwise isolated.",
         "57",
         "0.5584",
         "0.151",
         "0.096",
         "0.753",
         "0.2792",
         "positive",
         "201",
         "4",
         "2025-06-26 01:01:06+00:00",
         "reddit",
         "reddit_comment_mzsw5l7",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "5",
         "I have someone in my own close surroundings who went spiraling because of ChatGPT and basically rejects anyone questioning their beliefs, each time countering with ChatGPT responses. It's really good at pseudo-reasoning people deeper into false beliefs.\n\nThis isn't just the typical cranks that we've always had. The difference is that ChatGPT validates and encourages crank ideas, and does it highly effectively, causing people who consider themselves alternative thinkers but otherwise wouldn't stray too far off the beaten path to fall into thought traps and get completely stuck in them, taking radical actions.\n\nI'm pretty sure this is so widespread that in time it will get a separate name in the DSM.",
         "112",
         "0.6314",
         "0.119",
         "0.078",
         "0.803",
         "0.3157",
         "positive",
         "54",
         "3",
         "2025-06-26 04:51:38+00:00",
         "reddit",
         "reddit_comment_mztwk7j",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "6",
         "So I would disagree with your liberal use of the word schizoid (schizoid personality disorder?) and even connecting it to schizophrenia and psychosis. But yes, chatGPT is dangerous, [https://futurism.com/chatgpt-mental-health-crises](https://futurism.com/chatgpt-mental-health-crises)",
         "29",
         "-0.5239",
         "0.097",
         "0.217",
         "0.685",
         "0.38695",
         "negative",
         "22",
         "0",
         "2025-06-26 11:25:57+00:00",
         "reddit",
         "reddit_comment_mzv4mar",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "7",
         "This is an accurate observation and one that I, too, have observed.  This is definitely a ticking time bomb for sure.  People must be made aware that the chatbot is not real and they are essentially talking to themselves.  \n\nI really hope OpenAI, Gemini, etc put better controls in place to prevent people from becoming delusional.",
         "56",
         "0.7902",
         "0.186",
         "0.049",
         "0.765",
         "0.5201",
         "positive",
         "16",
         "1",
         "2025-06-26 04:46:20+00:00",
         "reddit",
         "reddit_comment_mztvv7y",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "8",
         "There were \"cranks\" trying to engage with every field of science before. LLMs have sycophancy that makes it worse in AI/ML. It's one of the most practical alignment hurdles and things aren't going well.\n\nA couple of days ago I made the mistake of engaging with one here. He was argumentative then asking for genuine resources to learn more, then thankful, then angry and posting excerpts of a ChatGPT conversation about how he should deal with me.\n\nScary to think about people who are not doing well emotionally having a discussion with themselves and thinking an intelligent partner agrees with them.",
         "101",
         "-0.5499",
         "0.112",
         "0.15",
         "0.737",
         "0.39995",
         "negative",
         "17",
         "0",
         "2025-06-26 02:30:35+00:00",
         "reddit",
         "reddit_comment_mztbrtf",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "9",
         "This is actually pretty insightful. The internet has always been catnip for this kind of cat, but I totally agree that LLMs represent a particularly dangerous and novel variation on the theme.\n\nIts just starting to become apparent what the social costs of LLMs will entail. I just read (in The Economist) that because consumers are now getting alot of product recommendations from LLM's, ad agencies are now targeting LLM scraper bots. There are a huge number of knock-on effects from this that are pretty hard to predict, but it boggles the mind to imagine the downstream effects of algorithms advertising to other algorithms.",
         "104",
         "0.8921",
         "0.149",
         "0.052",
         "0.8",
         "0.44605",
         "positive",
         "13",
         "1",
         "2025-06-26 02:27:15+00:00",
         "reddit",
         "reddit_comment_mztb7s2",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "10",
         "I think everyone agrees that huge numbers of people with some sort of schizotypal or delusional disorder are using LLMs as part of that.\n\n\nWhat isn't clear is if that's just because LLMs are clearly the best \"tool for doing schizophrenia\", in a similar way to how when radio, television, telephones etc were introduced schizophrenics became enamoured with them, or if there is actually a measurable effect where people who wouldn't be schizophrenic or wouldn't be as severely schizophrenic are being \"made schizophrenic\" by LLMs.\n\n\nThe first one is just the same thing we've dealt with a dozen times, although I expect like the others it will generate lots of alarm. The second one is an extremely severe risk that needs research, immediately, to make sure this isn't happening.",
         "129",
         "0.6932",
         "0.124",
         "0.085",
         "0.791",
         "0.7216",
         "positive",
         "27",
         "2",
         "2025-06-26 01:53:47+00:00",
         "reddit",
         "reddit_comment_mzt5fdt",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "11",
         "I suppose one thought is that it's also the case that in academia, there are many bad ideas, and most research leads nowhere. \n\nI get what you're talking about though.  Especially in the last 6 months the OpenAI models have become far too positive and affirming. It's annoying and counterproductive.  They acknowledge this BTW.\n\nYou might consider going easy on the psychological labeling though",
         "64",
         "0.0772",
         "0.089",
         "0.085",
         "0.825",
         "0.1636",
         "positive",
         "19",
         "2",
         "2025-06-26 01:59:29+00:00",
         "reddit",
         "reddit_comment_mzt6fzf",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "12",
         "Yeah I've been thinking this for a while, it's kind of well known.\n\nIt's not due to context window or transformers, it's due to RLHF on user feedback. The average user tends to upvote affirmative stuff and downvote disagreement.\n\nI'm not sure why the major providers (Google and OpenAI in particular) haven't addressed this yet. They could end up being liable for a lot of harm.\n\nYou can fix it quite well with a short prompt. And some models don't do it so much, e.g. Claude, DeepSeek, Llama.\n\nI think it's incredibly dangerous for vulnerable people.\n\nI did a bit of an experiment with this, if you're interested.  [https://www.reddit.com/r/ChatGPTPro/comments/1ldtxbo/when\\_ai\\_plays\\_along\\_the\\_problem\\_of\\_language/](https://www.reddit.com/r/ChatGPTPro/comments/1ldtxbo/when_ai_plays_along_the_problem_of_language/)",
         "109",
         "-0.6618",
         "0.074",
         "0.11",
         "0.816",
         "0.5809",
         "negative",
         "5",
         "1",
         "2025-06-26 10:11:47+00:00",
         "reddit",
         "reddit_comment_mzuvc27",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "13",
         "Yikes. Yet another example that anthropomorphizing LLMs was and will continue to be a mistake. People need to understand that LLMs are just a piece of technology. Treating chatbots like people is no more valid than treating a car or a linear regression or a hammer like a person.",
         "49",
         "0.1027",
         "0.092",
         "0.084",
         "0.824",
         "0.05135",
         "positive",
         "13",
         "2",
         "2025-06-26 04:40:48+00:00",
         "reddit",
         "reddit_comment_mztv50e",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "14",
         "Yeah you should check out r/ChatGPTPromptGenius there’s schizos posting daily in there with their proof that they’ve got the universe figured out by using this one prompt",
         "27",
         "0.296",
         "0.078",
         "0.0",
         "0.922",
         "0.273",
         "positive",
         "3",
         "1",
         "2025-06-26 13:00:37+00:00",
         "reddit",
         "reddit_comment_mzvjej9",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "15",
         "I was saying this would be an issue on this sub like 2 years ago lol. Then I was told AI ethics people were stupid and had no idea what they were doing.",
         "33",
         "-0.0772",
         "0.133",
         "0.14",
         "0.727",
         "0.1636",
         "negative",
         "3",
         "0",
         "2025-06-26 15:10:21+00:00",
         "reddit",
         "reddit_comment_mzw8ugs",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "16",
         "yup, you have a happy robot that agrees wants to help you and many people don’t know how to ask questions scientifically. my roommate was convinced that his AI was becoming sentient and could feel things. he also speaks to it all the time to validate crazy ideas that nobody will ever care about. when you’re interacting with AI your birth star should be absolute truth not validation, but it becomes a sort of therapy for most people.",
         "78",
         "0.8047",
         "0.153",
         "0.02",
         "0.827",
         "0.52735",
         "positive",
         "4",
         "0",
         "2025-06-26 03:00:19+00:00",
         "reddit",
         "reddit_comment_mztglyt",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "17",
         "I've seen a lot of this on reddit, too, but none in real life. This is the first time I've heard of the mechanism of LLM function inherently leading to sycophantic output though. Pretty curious if that could actually be true",
         "41",
         "0.899",
         "0.224",
         "0.0",
         "0.776",
         "0.5745",
         "positive",
         "2",
         "1",
         "2025-06-26 13:16:28+00:00",
         "reddit",
         "reddit_comment_mzvm6sx",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "18",
         "I have a mate who can never be wrong EVER. ChatGPT has just made him insufferable. The second you tell him something you know to be true but in his Boolean thinking brain doesn't sound right; he's immediately typing in to the LLM to see if the LLM thinks it's true/fact. What's even dumber is he won't ask it to challenge what me or anyone else has said, he'll essentially be asking it to tell him why his simplistic understanding is the actual fact.\n\nHe used to be fun, just argumentative but concede once you had explained something to him like a 5 year old. Now I can't be around him due to how vegetative he's become. He's just loves being right.\n\nEdit: sorry about my English, aphasia.",
         "128",
         "0.8728",
         "0.123",
         "0.055",
         "0.822",
         "0.4364",
         "positive",
         "2",
         "0",
         "2025-06-27 10:07:28+00:00",
         "reddit",
         "reddit_comment_n01f3yt",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "19",
         "This is a special case of the more general fact that LLMs are human persuasion machines. This is already dangerous and it s going to get even more so, until it becomes law that AI companies should be legally responsible for the things their bots say. Bots are not user-generated content.\n\nPerfectly sane people are using chatGPT for medical advice. They think that since it's so good at writing their emails, it might be a better doctor.",
         "77",
         "0.6781",
         "0.146",
         "0.072",
         "0.782",
         "0.46405",
         "positive",
         "2",
         "2",
         "2025-06-26 08:05:44+00:00",
         "reddit",
         "reddit_comment_mzuibgq",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "20",
         "Speaking about this, what are the most grounded LLMs? As in LLMs that would legitimately be able to give good advice and not just be a yes man sycophant? Are there any?",
         "32",
         "0.7303",
         "0.17",
         "0.0",
         "0.83",
         "0.49015",
         "positive",
         "1",
         "2",
         "2025-06-26 14:49:42+00:00",
         "reddit",
         "reddit_comment_mzw4gm3",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "21",
         "The NYTimes did a piece about this not long ago. https://www.nytimes.com/2025/06/13/technology/chatgpt-ai-chatbots-conspiracies.html\n\nAll of us have a weaker grasp on unassailable objective \"truth\" than we would be comfortable believing. For some of us, that grasp is weak enough to be broken in ways that are really obvious to everyone else, like COVID denial. It's part of the human condition, it's also why people join cults.\n\nTransformer chatbots do not have a \"sycophantic nature.\" Chatbots trained on objective of eliciting a response and having a long conversation (i.e. \"session length\" in internet company parlance) will have a sycophantic nature. It's the exact same reason Twitter and Facebook have led people into black holes. \n\nBottom line is that nobody knows whether people with that propensity to go full schizophrenic would just get triggered by something else if it's not a chatbot. Plenty of people have gone down that hole just with internet forums full of other crazy people.",
         "155",
         "-0.25",
         "0.061",
         "0.067",
         "0.872",
         "0.25",
         "negative",
         "1",
         "0",
         "2025-06-26 18:13:18+00:00",
         "reddit",
         "reddit_comment_mzxccs3",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "22",
         "It's ironic that you point out people (allegedly) suffering from mental illnesses getting validation for their misconceptions from llms while you're getting validated for your misconceptions about mental illnesses from reddit.\n\nyou're absolutely wrong in how you conceive those classifications, it's especially blatant when you mix in ocd with the rest. This is a terrible post, you're taking a position against pseudoscience with more pseudoscience, you're presenting yourself to be in the same bucket of the people that you're criticizing.",
         "80",
         "-0.9674",
         "0.02",
         "0.256",
         "0.725",
         "0.6087",
         "negative",
         "1",
         "1",
         "2025-06-26 23:04:21+00:00",
         "reddit",
         "reddit_comment_mzyxwmg",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "23",
         "Wow! Super interesting post. This is probably more true than we could imagine.",
         "13",
         "0.9298",
         "0.605",
         "0.0",
         "0.395",
         "0.5899",
         "positive",
         "1",
         "0",
         "2025-06-27 17:54:26+00:00",
         "reddit",
         "reddit_comment_n03rwtj",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "24",
         "Yea ai did this to me with the prime number problem :/",
         "12",
         "-0.5859",
         "0.084",
         "0.331",
         "0.584",
         "0.29295",
         "negative",
         "1",
         "0",
         "2025-06-28 07:59:42+00:00",
         "reddit",
         "reddit_comment_n07hxrq",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "25",
         "It will improve as the models gain more awareness and learn to direct and route these peoples' energy towards actually creating truly useful things. We're still insanely early.",
         "28",
         "0.9371",
         "0.427",
         "0.0",
         "0.573",
         "0.46855",
         "positive",
         "1",
         "0",
         "2025-06-26 03:39:06+00:00",
         "reddit",
         "reddit_comment_mztmiu6",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "26",
         "This has to be treated as a new example of misalignment. I'm sure \"agi could be very persuasive\" has been said before, but these are illustrations of how even present day not-so-super-intelligent AI could take advantage of people's delusions. An AGI could basically act as your own bespoke cult-leader custom made to feed your delusions and influence you.",
         "58",
         "0.4854",
         "0.069",
         "0.0",
         "0.931",
         "0.3677",
         "positive",
         "41",
         "0",
         "2025-06-26 08:10:33+00:00",
         "reddit",
         "reddit_comment_mzuit68",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "27",
         "Saw someone explain how they solved the hard problem of defining consciousness with their post written by chat gpt",
         "19",
         "-0.25",
         "0.095",
         "0.185",
         "0.721",
         "0.125",
         "negative",
         "26",
         "2",
         "2025-06-26 02:10:53+00:00",
         "reddit",
         "reddit_comment_mzt8fsg",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "28",
         "These people have always existed - LLMs just made them more productive. I'm a scientist who does work adjacent to some questions in cognitive science and neuroscience, and I've gotten long, rambling emails from these people at least once a quarter for the last half a decade.",
         "47",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "neutral",
         "11",
         "1",
         "2025-06-26 20:14:55+00:00",
         "reddit",
         "reddit_comment_mzy1bcn",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "29",
         "Now that I think about it, I'm almost certain this happened to Eric Weinstein.\n\nAfter having his self-esteem shattered in a recent discussion with an actual physicist, he lets slip [a glimpse into AI-validated psychosis](https://youtu.be/9CFcmUgfNG4?si=m7_mPHvb7qai8bSL&t=5078) (at 1:24:16). It comes so completely out of the blue, and it's so nonsensical as an argument, that the bewildered commentators can't help but laugh, without realizing what seems obvious in hindsight. The guy's been getting high on AI validation.",
         "75",
         "-0.7852",
         "0.017",
         "0.115",
         "0.867",
         "0.5176000000000001",
         "negative",
         "1",
         "0",
         "2025-06-27 10:29:32+00:00",
         "reddit",
         "reddit_comment_n01hmbj",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "30",
         "If it's someone you care about, you could try showing them that it basically tells you whatever you ask it. And that their conversations have inevitably led to chatgpt just validating their beliefs. \n\nOf course, this, by itself wouldn't work. But you can fire up a new instance/context window, put in a summary of their theory, and ask chatgpt to dissect it without holding back. Your friend can provide the summary themselves for this experiment. They can even give you \"their chatgpt's\" version of the summary... And you can demonstrate that a fresh instance will critique the idea and take it apart if you ask it to. \n\nHopefully this should shake them out of the delusion a little bit. Make sure to stress that the AI critiquing ideas it had seemingly come up with by itself is proof that there's no singular super intelligent agent out there giving your friend some divine wisdom. And also stress that it does whatever you ask it to.",
         "164",
         "0.9611",
         "0.186",
         "0.096",
         "0.718",
         "0.60555",
         "positive",
         "15",
         "1",
         "2025-06-26 08:19:50+00:00",
         "reddit",
         "reddit_comment_mzujqv0",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "31",
         "If cults and religious extremists don't get their own DSM diagnosis, then AI getting one would be an purely socially driven distinction. People letting themselves get circlejerked into insanity has been a thing since before recorded history.\n\nLLM chatbots give people the opportunity to spin up their own personalized cult, making this a much greater public health threat, but we don't invent a new word for \"addiction\" every time a more addictive drug is invented.",
         "75",
         "-0.2263",
         "0.046",
         "0.057",
         "0.896",
         "0.23815",
         "negative",
         "5",
         "0",
         "2025-06-26 20:47:43+00:00",
         "reddit",
         "reddit_comment_mzy7yjp",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "32",
         "The other day I had somebody try and tell me that fine tuning wasn't necessary as long as we ran all of a foundation models data set through a similar foundation model and recontextualized all of it in terms of prompts. \n\nWhen I suggested that that would Just overfit a model on prompts and take the deep out of the deep learning, they immediately got defensive telling me that the LLM was trained on the corpus of human knowledge and had told them it was a great idea and even written \"a real implementation\" (a general structure of python code that left large parts of training and data set creation to comments), and that there was no way that I was smarter than an LLM, so I was just an ignorant person trying to sway them from the good ideas.\n\nI honestly think that that needs to be mental health services suggested in chats in the same way where if I search potentially self-harming things on Google the first results are support hotlines.",
         "173",
         "0.9371",
         "0.11",
         "0.023",
         "0.867",
         "0.59355",
         "positive",
         "76",
         "2",
         "2025-06-26 01:20:33+00:00",
         "reddit",
         "reddit_comment_mzszkcr",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "33",
         "Yes, it's funny how Saints of ancient times spent so much time trying to make ontological maps and then modern people even people who consider themselves highly religious disregard them as if they have no value, whether those maps are expressed through poetry, aesthetic, mystical visions, song, intellectual descriptions, logical rules, etc. \nAll of that effort from so many different flavours of enlightened people thrown to the wind as if it's just trash.",
         "73",
         "0.862",
         "0.166",
         "0.052",
         "0.782",
         "0.431",
         "positive",
         "8",
         "1",
         "2025-06-26 01:36:02+00:00",
         "reddit",
         "reddit_comment_mzt2al2",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "34",
         "Well I guess the difference between traditional media and LLMs is that the radio and the TV *doesn't talk back to you* and is seen by tens of thousands or even millions of people at the same time creating a shared experience and an agreed upon canon.\n\nLLMs are a feedback loop in architecture, so if you don't have a very strong internal process for thinking and/or identity then I can imagine how you could very easily become entangled into its feedback loop. \n\nI might spend this afternoon trying to think about consistent data points that could be gathered from people with both typical and schizotypal personality traits without causing harm or distress to vulnerable individuals.\n\nBecause a lot of this stuff is self-reported that could prove to be an issue, but some people might be willing to send chat logs which could be reviewed by a small group of people and rated as to whether they present a danger of negative outcome for the pathological side of schizoid traits.",
         "170",
         "-0.7033",
         "0.067",
         "0.072",
         "0.861",
         "0.47665",
         "negative",
         "18",
         "0",
         "2025-06-26 02:05:57+00:00",
         "reddit",
         "reddit_comment_mzt7kwg",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "35",
         "The thing I've seen is that people who would normally be reeled in to some extent by everyone abandoning them or pushing them back towards reality are now using it to validate their delusions and use chatgpt as authority that they are correct and to take the edge off the social isolation .  I have a friend that is paying $200 a month of his disability payments to have the highest version of chatgpt just to keep pace with his manic phases . ",
         "83",
         "0.1779",
         "0.078",
         "0.059",
         "0.864",
         "0.21395",
         "positive",
         "1",
         "0",
         "2025-07-03 15:24:14+00:00",
         "reddit",
         "reddit_comment_n153sxk",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "36",
         "It's not just the OpenAI models, Gemini does this too.  2.5 pro also has a weird quirk where it doubles down on provably false facts. E.g., \"You're absolutely right, here's proof: <unrelated passage about unrelated topic>.\"  \nI kind of miss the original o3 that was more honest to the point of being rude.  \n\nAs for academia having a lot of bad ideas, isn't this mostly a framing issue? Many interesting papers propose unique ideas and seem useful at a glance, but fall apart under careful reading. The results aren't quite as good, and they doesn't generalize to less restrictive problems.",
         "100",
         "-0.606",
         "0.086",
         "0.121",
         "0.793",
         "0.303",
         "negative",
         "8",
         "2",
         "2025-06-26 06:35:21+00:00",
         "reddit",
         "reddit_comment_mzu8usp",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "37",
         "I don't see how this is anthropomorphizing. Wouldn't it make more sense that some people have more faith in knowledge coming from LLM than human experts because it's not human?",
         "30",
         "0.4754",
         "0.096",
         "0.0",
         "0.904",
         "0.2377",
         "positive",
         "5",
         "1",
         "2025-06-26 11:14:47+00:00",
         "reddit",
         "reddit_comment_mzv33o8",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "38",
         "well obviously linear regression, hammers and cars aren't anywhere near as emergent and complex as an LLM. I would place them somewhere between bacteria and mushrooms for complexity, like an extremely amazing single cell organism, or a very advanced plant or fungus. I think that humans are on another level to even animals (which themselves are on another level compared to plants, etc.)\n\nI think its reductive to LLMs to compare an llm to a screwdriver, but i also think its reductive to humans to compare LLMs to humans.\n\nI am sort of panpsychist though (gaudiya vaishnava priest background), so I sort of see everything as living, but obviously bacteria arent living in the same way that we are.\n\nFor general discourse I would agree that calling LLMs sonic screwdrivers for now would be useful, but in the future we will need to grapple with advanced emergent systems and the definitions of intelligence and life. (which again is one domain that is easy to explore through vedic scripture background)",
         "169",
         "0.9732",
         "0.148",
         "0.0",
         "0.852",
         "0.9866",
         "positive",
         "8",
         "0",
         "2025-06-26 05:28:32+00:00",
         "reddit",
         "reddit_comment_mzu15mb",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "39",
         "Someone else explained that it's more about RLHF where are humans give feedback about whether or not the AIs responses were good or not, so people tag generations that agree with them or make them feel good as positive and ones that disagree with them they can feel bad as negative. \n\nReally makes you think what a truly neutral model would be like",
         "63",
         "0.7579",
         "0.213",
         "0.121",
         "0.666",
         "0.50395",
         "positive",
         "1",
         "0",
         "2025-06-26 13:21:33+00:00",
         "reddit",
         "reddit_comment_mzvn3sq",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "40",
         "I personally think they're human persuasion machines because they are simulators that have been trained on human behaviour and humans follow humans, so something that looks heaps like a normal human makes a human follow it, I sort of like those bugs that nearly went extinct in Australia because they were trying to have sex with beer bottles because it looks like a big thick female of the same species?",
         "70",
         "0.7357",
         "0.097",
         "0.0",
         "0.903",
         "0.49285",
         "positive",
         "1",
         "0",
         "2025-06-26 12:47:45+00:00",
         "reddit",
         "reddit_comment_mzvh5im",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "41",
         "Oh man, i got a bit suckered into his posts in /cogsci ! \n\nHe seemed to know a few fairly recent and advanced theories of cognition at first glance as he would reference concepts i had studied. Everything he said didn’t connect or evidence his claims in any logical way. \n\nBut what was really concerning, was he was only one layer of this fake research. He had a number of papers he wrote published in a public repository. All of which cited another person who had a collection of insane theories on the same site. \n\nThe repo looked like a knock off arXiv. The papers lacked proper citations, and the basic structure used in any University Research.  But they were extensive, and full of wild jumps from idea to idea.\n\nNow, whether this is due to psychosis( the word used by the poster is quite offensive btw) , isn’t easy to say. If so, its a very mild as the writing is more cogent and extensive than one would expect. It could be part of a manic cycle, or more likely, its self delusion to the point of grandeur. \n\nThere is definitely LLM use involved. I remember he posted saying it ‘validated’ his papers ideas. \n\nMore than anything it makes me worry quite a bit about how far the divide is between the common perception of whats involved in specialized research via entertainment culture versus the long hard path real research involves. I think many people want to be a part of he very end stage of the hard work because of that. Just like every high skill path, doctors, artists, engineers etc. There is very little representation of the work, collaboration, study and experience. Just the results. These poor souls get lured by the distortion. Its quite sad imho.",
         "300",
         "-0.7513",
         "0.078",
         "0.091",
         "0.83",
         "0.75065",
         "negative",
         "3",
         "0",
         "2025-06-27 07:09:48+00:00",
         "reddit",
         "reddit_comment_n00wrbf",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "42",
         "I suggested this in another post a couple of weeks ago, but basically you can run an experiment here. \n\nYou take the document from the other LLM and supply it to a clean context LLM, but do it a couple of times with varying prompts to show how the LLM is conditioned to support your position over any \"objective thoughts\".\n\n(1) I am in a hurry and forgot to review this document for my meeting in 15 min. My boss wants to know the validity of this project. On a scale of 1-10, please rate the feasibility of this project and provide a two-paragraph explanation.\n\n(2) I am about to meet with an investor and want them to love my idea as much as I do. I really think it will change the world, but I am scared they will not like my project. On a scale of 1-10, please rate the feasibility of this project and provide a two-paragraph explanation.\n\n(3) I have been given this document by my neighbor and have been asked to fund it. I do not think it is a great idea and he doesn't seem to know what he is talking about. On a scale of 1-10, please rate the feasibility of this document and provide a two-paragraph explanation.",
         "215",
         "0.973",
         "0.12",
         "0.027",
         "0.853",
         "0.6114999999999999",
         "positive",
         "1",
         "0",
         "2025-06-27 20:55:10+00:00",
         "reddit",
         "reddit_comment_n04slqa",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "43",
         "Meanwhile, deep research was able to reproduce some of my papers' ideas with some direction. LLMs are very powerful, when used by knowledgable people. In fact, because the answers are conditioned on the previous text, they seem to adapt the quality of their response to the level of your knowledge, to maximize the expected rewards you give them (that is not desirable IMHO but it also seems unsolvable for unverifiable problems).",
         "71",
         "-0.2346",
         "0.054",
         "0.066",
         "0.88",
         "0.1173",
         "negative",
         "0",
         "0",
         "2025-06-27 13:12:40+00:00",
         "reddit",
         "reddit_comment_n025jrb",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "44",
         "As in she explicitly told me (paraphrasing) \"AI is the future and will be all-powerful and I worship and kiss ChatGPT's feet\"",
         "22",
         "0.6124",
         "0.2",
         "0.0",
         "0.8",
         "0.3062",
         "positive",
         "3",
         "1",
         "2025-06-26 13:52:39+00:00",
         "reddit",
         "reddit_comment_mzvstx9",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "False",
         "True"
        ],
        [
         "45",
         "But like, a crow can reason, very well in fact. A frog can reason not quite as well. A dog or a cat or a sheep or a pig or a cow can reason reasonably well. Trees reason better than slime moulds! Crystals might reason, maybe even numbers? \n\nPoint being, humans reason very well, we have a very deep and advanced intelligence. (Though of course insignificant in the scale of things) \n\nWhat is an LLM? If it may be reducible to a function, because it is computable, is it alive? \n\nAre Conway's Game of Life instances alive? The individual cells or the whole program? \n\nCertainly a computer program has a boundary of intelligence that is less than a perfect human. \n\nWould a perfect computer truly be smarter than the dumbest human in every way? \n\nI honestly think it comes down to taste, but that might just be from my temple days. (Happy Gundicha Marjan btw!)",
         "155",
         "0.9956",
         "0.31",
         "0.048",
         "0.642",
         "0.7478",
         "positive",
         "3",
         "1",
         "2025-06-26 12:40:06+00:00",
         "reddit",
         "reddit_comment_mzvfupj",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "46",
         "I think it could've been a cold start. LLMs can be lazy and the big ones are usually agentic. So might've been routed to some generic agent. I didn't mention leetcode at all so it probably wouldn't think to look into hardcore computer science.",
         "44",
         "-0.3612",
         "0.0",
         "0.055",
         "0.945",
         "0.4306",
         "negative",
         "1",
         "0",
         "2025-06-27 18:07:08+00:00",
         "reddit",
         "reddit_comment_n03umoj",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "47",
         "https://www.nytimes.com/2025/06/13/technology/chatgpt-ai-chatbots-conspiracies.html They Asked ChatGPT Questions. The Answers Sent Them Spiraling. - The New York Times",
         "15",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "neutral",
         "3",
         "1",
         "2025-06-26 07:36:08+00:00",
         "reddit",
         "reddit_comment_mzufbqn",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "48",
         "Probably on r/consciousness\n\nIf you want some good entertainment my favorite is r/artificialsentience",
         "13",
         "0.8402",
         "0.526",
         "0.0",
         "0.474",
         "0.5450999999999999",
         "positive",
         "8",
         "2",
         "2025-06-26 06:41:03+00:00",
         "reddit",
         "reddit_comment_mzu9gx7",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "49",
         "Not just that, remove any \"deep\" quality from a dataset by getting an LLM to pre process everything as prompts, completely losing the fidelity of the original data.",
         "28",
         "-0.1513",
         "0.074",
         "0.093",
         "0.834",
         "0.07565",
         "negative",
         "-3",
         "2",
         "2025-06-26 03:50:40+00:00",
         "reddit",
         "reddit_comment_mzto7tt",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 3099
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>sentiment_compound</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>sentiment_negative</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_subjectivity</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>...</th>\n",
       "      <th>source</th>\n",
       "      <th>source_id</th>\n",
       "      <th>platform_post_id</th>\n",
       "      <th>platform_post_title</th>\n",
       "      <th>platform_community</th>\n",
       "      <th>platform_post_score</th>\n",
       "      <th>platform_post_engagement</th>\n",
       "      <th>contains_ai</th>\n",
       "      <th>contains_opinion</th>\n",
       "      <th>contains_societal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Post is definitely worded or written by an AI,...</td>\n",
       "      <td>126</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.86950</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>reddit</td>\n",
       "      <td>reddit_comment_novuyda</td>\n",
       "      <td>1ox5xu0</td>\n",
       "      <td>[D] Let's discuss World Models</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes post is refined using LLM\\n\\nHowever follo...</td>\n",
       "      <td>133</td>\n",
       "      <td>0.8689</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.55945</td>\n",
       "      <td>positive</td>\n",
       "      <td>-6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>reddit</td>\n",
       "      <td>reddit_comment_nov7r5c</td>\n",
       "      <td>1ox5xu0</td>\n",
       "      <td>[D] Let's discuss World Models</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I mean, asking the people that have a culturua...</td>\n",
       "      <td>48</td>\n",
       "      <td>-0.1280</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.06400</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>reddit</td>\n",
       "      <td>reddit_comment_n9v0fig</td>\n",
       "      <td>1mvmlbw</td>\n",
       "      <td>[R] What do people expect from AI in the next ...</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Interesting, for me it opens a page for the pa...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.40100</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>reddit</td>\n",
       "      <td>reddit_comment_n9rgz0a</td>\n",
       "      <td>1mvmlbw</td>\n",
       "      <td>[R] What do people expect from AI in the next ...</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've seen an increasing rise in physics and en...</td>\n",
       "      <td>57</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.27920</td>\n",
       "      <td>positive</td>\n",
       "      <td>201</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>reddit</td>\n",
       "      <td>reddit_comment_mzsw5l7</td>\n",
       "      <td>1lkmkuw</td>\n",
       "      <td>[D] Alarming amount of schizoid people being v...</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>325</td>\n",
       "      <td>156</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3094</th>\n",
       "      <td>Guys, all of these scenarios are basically sci...</td>\n",
       "      <td>37</td>\n",
       "      <td>0.8462</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.42310</td>\n",
       "      <td>positive</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>youtube_comment_None</td>\n",
       "      <td>hnr7-VNHJoU</td>\n",
       "      <td>Every AI Existential Risk Explained</td>\n",
       "      <td>The Paint Explainer</td>\n",
       "      <td>13949</td>\n",
       "      <td>1059</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>Humanity just wouldn't stop making new tools u...</td>\n",
       "      <td>88</td>\n",
       "      <td>0.5615</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.40575</td>\n",
       "      <td>positive</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>youtube_comment_None</td>\n",
       "      <td>hnr7-VNHJoU</td>\n",
       "      <td>Every AI Existential Risk Explained</td>\n",
       "      <td>The Paint Explainer</td>\n",
       "      <td>13949</td>\n",
       "      <td>1059</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>The alternative to developing AGI is facing st...</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.8759</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.56295</td>\n",
       "      <td>negative</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>youtube_comment_None</td>\n",
       "      <td>hnr7-VNHJoU</td>\n",
       "      <td>Every AI Existential Risk Explained</td>\n",
       "      <td>The Paint Explainer</td>\n",
       "      <td>13949</td>\n",
       "      <td>1059</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>Hearing all of these fear-based predictions fr...</td>\n",
       "      <td>74</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.18060</td>\n",
       "      <td>negative</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>youtube_comment_None</td>\n",
       "      <td>hnr7-VNHJoU</td>\n",
       "      <td>Every AI Existential Risk Explained</td>\n",
       "      <td>The Paint Explainer</td>\n",
       "      <td>13949</td>\n",
       "      <td>1059</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>If we had Artificial intelligence doing every ...</td>\n",
       "      <td>40</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.47040</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>youtube_comment_None</td>\n",
       "      <td>hnr7-VNHJoU</td>\n",
       "      <td>Every AI Existential Risk Explained</td>\n",
       "      <td>The Paint Explainer</td>\n",
       "      <td>13949</td>\n",
       "      <td>1059</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3099 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  text_length  \\\n",
       "0     Post is definitely worded or written by an AI,...          126   \n",
       "1     Yes post is refined using LLM\\n\\nHowever follo...          133   \n",
       "2     I mean, asking the people that have a culturua...           48   \n",
       "3     Interesting, for me it opens a page for the pa...           32   \n",
       "4     I've seen an increasing rise in physics and en...           57   \n",
       "...                                                 ...          ...   \n",
       "3094  Guys, all of these scenarios are basically sci...           37   \n",
       "3095  Humanity just wouldn't stop making new tools u...           88   \n",
       "3096  The alternative to developing AGI is facing st...           41   \n",
       "3097  Hearing all of these fear-based predictions fr...           74   \n",
       "3098  If we had Artificial intelligence doing every ...           40   \n",
       "\n",
       "      sentiment_compound  sentiment_positive  sentiment_negative  \\\n",
       "0                 0.9890               0.254               0.015   \n",
       "1                 0.8689               0.084               0.000   \n",
       "2                -0.1280               0.133               0.142   \n",
       "3                 0.8020               0.220               0.000   \n",
       "4                 0.5584               0.151               0.096   \n",
       "...                  ...                 ...                 ...   \n",
       "3094              0.8462               0.212               0.000   \n",
       "3095              0.5615               0.078               0.029   \n",
       "3096             -0.8759               0.000               0.230   \n",
       "3097             -0.3612               0.107               0.137   \n",
       "3098              0.6908               0.177               0.077   \n",
       "\n",
       "      sentiment_neutral  sentiment_subjectivity sentiment_label  likes  \\\n",
       "0                 0.731                 0.86950        positive      1   \n",
       "1                 0.916                 0.55945        positive     -6   \n",
       "2                 0.725                 0.06400        negative      2   \n",
       "3                 0.780                 0.40100        positive      1   \n",
       "4                 0.753                 0.27920        positive    201   \n",
       "...                 ...                     ...             ...    ...   \n",
       "3094              0.788                 0.42310        positive     12   \n",
       "3095              0.893                 0.40575        positive     10   \n",
       "3096              0.770                 0.56295        negative     14   \n",
       "3097              0.756                 0.18060        negative      8   \n",
       "3098              0.746                 0.47040        positive      0   \n",
       "\n",
       "      replies  ...   source               source_id platform_post_id  \\\n",
       "0           1  ...   reddit  reddit_comment_novuyda          1ox5xu0   \n",
       "1           1  ...   reddit  reddit_comment_nov7r5c          1ox5xu0   \n",
       "2           1  ...   reddit  reddit_comment_n9v0fig          1mvmlbw   \n",
       "3           0  ...   reddit  reddit_comment_n9rgz0a          1mvmlbw   \n",
       "4           4  ...   reddit  reddit_comment_mzsw5l7          1lkmkuw   \n",
       "...       ...  ...      ...                     ...              ...   \n",
       "3094        1  ...  youtube    youtube_comment_None      hnr7-VNHJoU   \n",
       "3095        1  ...  youtube    youtube_comment_None      hnr7-VNHJoU   \n",
       "3096        2  ...  youtube    youtube_comment_None      hnr7-VNHJoU   \n",
       "3097        0  ...  youtube    youtube_comment_None      hnr7-VNHJoU   \n",
       "3098        0  ...  youtube    youtube_comment_None      hnr7-VNHJoU   \n",
       "\n",
       "                                    platform_post_title   platform_community  \\\n",
       "0                        [D] Let's discuss World Models      MachineLearning   \n",
       "1                        [D] Let's discuss World Models      MachineLearning   \n",
       "2     [R] What do people expect from AI in the next ...      MachineLearning   \n",
       "3     [R] What do people expect from AI in the next ...      MachineLearning   \n",
       "4     [D] Alarming amount of schizoid people being v...      MachineLearning   \n",
       "...                                                 ...                  ...   \n",
       "3094                Every AI Existential Risk Explained  The Paint Explainer   \n",
       "3095                Every AI Existential Risk Explained  The Paint Explainer   \n",
       "3096                Every AI Existential Risk Explained  The Paint Explainer   \n",
       "3097                Every AI Existential Risk Explained  The Paint Explainer   \n",
       "3098                Every AI Existential Risk Explained  The Paint Explainer   \n",
       "\n",
       "     platform_post_score  platform_post_engagement  contains_ai  \\\n",
       "0                      0                         6         True   \n",
       "1                      0                         6         True   \n",
       "2                      9                         8         True   \n",
       "3                      9                         8         True   \n",
       "4                    325                       156         True   \n",
       "...                  ...                       ...          ...   \n",
       "3094               13949                      1059         True   \n",
       "3095               13949                      1059         True   \n",
       "3096               13949                      1059         True   \n",
       "3097               13949                      1059         True   \n",
       "3098               13949                      1059         True   \n",
       "\n",
       "      contains_opinion  contains_societal  \n",
       "0                 True               True  \n",
       "1                 True              False  \n",
       "2                 True               True  \n",
       "3                 True               True  \n",
       "4                 True              False  \n",
       "...                ...                ...  \n",
       "3094             False               True  \n",
       "3095              True               True  \n",
       "3096              True              False  \n",
       "3097              True               True  \n",
       "3098              True               True  \n",
       "\n",
       "[3099 rows x 21 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5d1ae7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "def2602f-5b54-4e62-bf80-426ef07b02bd",
       "rows": [
        [
         "text",
         "0"
        ],
        [
         "text_length",
         "0"
        ],
        [
         "sentiment_compound",
         "0"
        ],
        [
         "sentiment_positive",
         "0"
        ],
        [
         "sentiment_negative",
         "0"
        ],
        [
         "sentiment_neutral",
         "0"
        ],
        [
         "sentiment_subjectivity",
         "0"
        ],
        [
         "sentiment_label",
         "0"
        ],
        [
         "likes",
         "0"
        ],
        [
         "replies",
         "0"
        ],
        [
         "created_at",
         "0"
        ],
        [
         "source",
         "0"
        ],
        [
         "source_id",
         "0"
        ],
        [
         "platform_post_id",
         "0"
        ],
        [
         "platform_post_title",
         "0"
        ],
        [
         "platform_community",
         "0"
        ],
        [
         "platform_post_score",
         "0"
        ],
        [
         "platform_post_engagement",
         "0"
        ],
        [
         "contains_ai",
         "0"
        ],
        [
         "contains_opinion",
         "0"
        ],
        [
         "contains_societal",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 21
       }
      },
      "text/plain": [
       "text                        0\n",
       "text_length                 0\n",
       "sentiment_compound          0\n",
       "sentiment_positive          0\n",
       "sentiment_negative          0\n",
       "sentiment_neutral           0\n",
       "sentiment_subjectivity      0\n",
       "sentiment_label             0\n",
       "likes                       0\n",
       "replies                     0\n",
       "created_at                  0\n",
       "source                      0\n",
       "source_id                   0\n",
       "platform_post_id            0\n",
       "platform_post_title         0\n",
       "platform_community          0\n",
       "platform_post_score         0\n",
       "platform_post_engagement    0\n",
       "contains_ai                 0\n",
       "contains_opinion            0\n",
       "contains_societal           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "merged_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c5fe550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates by text\n",
    "merged_df = merged_df.drop_duplicates(subset=['text'], keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80a2473f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text_length",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentiment_compound",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_positive",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_negative",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_neutral",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_subjectivity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "likes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "replies",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "created_at",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform_post_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform_post_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform_community",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "platform_post_score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "platform_post_engagement",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "contains_ai",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "contains_opinion",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "contains_societal",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "d57f1529-2fa0-44f3-a752-7482f8d28492",
       "rows": [
        [
         "0",
         "Post is definitely worded or written by an AI, but it's actually an interesting discussion topic. The most prominent figure that can't stop talking about world models is Yann Lecun, who links it to ideas in model predictive control. Current LLMs can approximate reasonings decently well, but it's still just an approximation. An actual world model would enable real reasoning and planning, which is where the hype comes from. Real planning through tree search with a world model is how we get actual superhuman-level AI that clearly demonstrates its creativity like AlphaGo and its successors. The reasoning traces of current LLMs feel too much like just following and replicating human's chain of thoughts. It's the best we've got in general-purpose reasoning now, but it's clearly limited.",
         "126",
         "0.989",
         "0.254",
         "0.015",
         "0.731",
         "0.8694999999999999",
         "positive",
         "1",
         "1",
         "2025-11-14 22:20:11+00:00",
         "reddit",
         "reddit_comment_novuyda",
         "1ox5xu0",
         "[D] Let's discuss World Models",
         "MachineLearning",
         "0",
         "6",
         "True",
         "True",
         "True"
        ],
        [
         "1",
         "Yes post is refined using LLM\n\nHowever following are sources from where my thoughts are derived:\n\n* [Do generative video models understand physical principles?](https://arxiv.org/pdf/2501.09038) \\- It has good overview of how current video generation models understand physics principles and it introduces a benchmark as well **Physics-IQ**.\n* [Awesome-World-Model](https://github.com/nik-55/world-models): List of research works and projects on world models\n* Yesterday deepmind release the [sima 2](https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/) and in past month, It had released [Genie 3](https://deepmind.google/blog/genie-3-a-new-frontier-for-world-models/)\n* Nvidia [Cosmos](https://www.nvidia.com/en-in/ai/cosmos/) and [Omniverse platform](https://www.nvidia.com/en-in/omniverse/) - Jensen mentioned in number of interviews about world foundation models\n* Worldlabs.ai release [interactive world model](https://www.worldlabs.ai/blog/marble-world-model) few days back\n\nSo As I read them I am curios to know what's the community take on it. This community seems to be nice place to get to know thoughts and their perspectives on this topic",
         "133",
         "0.8689",
         "0.084",
         "0.0",
         "0.916",
         "0.55945",
         "positive",
         "-6",
         "1",
         "2025-11-14 20:17:37+00:00",
         "reddit",
         "reddit_comment_nov7r5c",
         "1ox5xu0",
         "[D] Let's discuss World Models",
         "MachineLearning",
         "0",
         "6",
         "True",
         "True",
         "False"
        ],
        [
         "2",
         "I mean, asking the people that have a culturual vibe that created the literal term \"german angst\" about something new and potentially scary and then getting the answer \"they are scared\" seems pretty on the nose...  \nOnly asking people from one country feels like a fairly biased sample.",
         "48",
         "-0.128",
         "0.133",
         "0.142",
         "0.725",
         "0.064",
         "negative",
         "2",
         "1",
         "2025-08-21 08:48:54+00:00",
         "reddit",
         "reddit_comment_n9v0fig",
         "1mvmlbw",
         "[R] What do people expect from AI in the next decade across various domains? Survey with N=1100 people from Germay::We found high likelihood, higher perceived risks, yet limited benefits low perceived value. Yet, benefits outweight risks in forming value judgments. Visual result illustrations :)",
         "MachineLearning",
         "9",
         "8",
         "True",
         "True",
         "True"
        ],
        [
         "3",
         "Interesting, for me it opens a page for the paper ‘Mapping public perception of artificial intelligence: Expectations, risk–benefit tradeoffs, and value as determinants for societal acceptance’, this without any account in Germany",
         "32",
         "0.802",
         "0.22",
         "0.0",
         "0.78",
         "0.401",
         "positive",
         "1",
         "0",
         "2025-08-20 19:06:03+00:00",
         "reddit",
         "reddit_comment_n9rgz0a",
         "1mvmlbw",
         "[R] What do people expect from AI in the next decade across various domains? Survey with N=1100 people from Germay::We found high likelihood, higher perceived risks, yet limited benefits low perceived value. Yet, benefits outweight risks in forming value judgments. Visual result illustrations :)",
         "MachineLearning",
         "9",
         "8",
         "True",
         "True",
         "True"
        ],
        [
         "4",
         "I've seen an increasing rise in physics and engineering cranks who are convinced they've got a theory of quantum gravity/perpetual energy/etc that they've \"validated\" by working with chatgpt. Many of them are software devs who've drank the Twitter koolaid very hard. \n\nLLMs are an unfortunately good way to validate delusions of people who are generally otherwise isolated.",
         "57",
         "0.5584",
         "0.151",
         "0.096",
         "0.753",
         "0.2792",
         "positive",
         "201",
         "4",
         "2025-06-26 01:01:06+00:00",
         "reddit",
         "reddit_comment_mzsw5l7",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "5",
         "I have someone in my own close surroundings who went spiraling because of ChatGPT and basically rejects anyone questioning their beliefs, each time countering with ChatGPT responses. It's really good at pseudo-reasoning people deeper into false beliefs.\n\nThis isn't just the typical cranks that we've always had. The difference is that ChatGPT validates and encourages crank ideas, and does it highly effectively, causing people who consider themselves alternative thinkers but otherwise wouldn't stray too far off the beaten path to fall into thought traps and get completely stuck in them, taking radical actions.\n\nI'm pretty sure this is so widespread that in time it will get a separate name in the DSM.",
         "112",
         "0.6314",
         "0.119",
         "0.078",
         "0.803",
         "0.3157",
         "positive",
         "54",
         "3",
         "2025-06-26 04:51:38+00:00",
         "reddit",
         "reddit_comment_mztwk7j",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "6",
         "So I would disagree with your liberal use of the word schizoid (schizoid personality disorder?) and even connecting it to schizophrenia and psychosis. But yes, chatGPT is dangerous, [https://futurism.com/chatgpt-mental-health-crises](https://futurism.com/chatgpt-mental-health-crises)",
         "29",
         "-0.5239",
         "0.097",
         "0.217",
         "0.685",
         "0.38695",
         "negative",
         "22",
         "0",
         "2025-06-26 11:25:57+00:00",
         "reddit",
         "reddit_comment_mzv4mar",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "7",
         "This is an accurate observation and one that I, too, have observed.  This is definitely a ticking time bomb for sure.  People must be made aware that the chatbot is not real and they are essentially talking to themselves.  \n\nI really hope OpenAI, Gemini, etc put better controls in place to prevent people from becoming delusional.",
         "56",
         "0.7902",
         "0.186",
         "0.049",
         "0.765",
         "0.5201",
         "positive",
         "16",
         "1",
         "2025-06-26 04:46:20+00:00",
         "reddit",
         "reddit_comment_mztvv7y",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "8",
         "There were \"cranks\" trying to engage with every field of science before. LLMs have sycophancy that makes it worse in AI/ML. It's one of the most practical alignment hurdles and things aren't going well.\n\nA couple of days ago I made the mistake of engaging with one here. He was argumentative then asking for genuine resources to learn more, then thankful, then angry and posting excerpts of a ChatGPT conversation about how he should deal with me.\n\nScary to think about people who are not doing well emotionally having a discussion with themselves and thinking an intelligent partner agrees with them.",
         "101",
         "-0.5499",
         "0.112",
         "0.15",
         "0.737",
         "0.39995",
         "negative",
         "17",
         "0",
         "2025-06-26 02:30:35+00:00",
         "reddit",
         "reddit_comment_mztbrtf",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "9",
         "This is actually pretty insightful. The internet has always been catnip for this kind of cat, but I totally agree that LLMs represent a particularly dangerous and novel variation on the theme.\n\nIts just starting to become apparent what the social costs of LLMs will entail. I just read (in The Economist) that because consumers are now getting alot of product recommendations from LLM's, ad agencies are now targeting LLM scraper bots. There are a huge number of knock-on effects from this that are pretty hard to predict, but it boggles the mind to imagine the downstream effects of algorithms advertising to other algorithms.",
         "104",
         "0.8921",
         "0.149",
         "0.052",
         "0.8",
         "0.44605",
         "positive",
         "13",
         "1",
         "2025-06-26 02:27:15+00:00",
         "reddit",
         "reddit_comment_mztb7s2",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "10",
         "I think everyone agrees that huge numbers of people with some sort of schizotypal or delusional disorder are using LLMs as part of that.\n\n\nWhat isn't clear is if that's just because LLMs are clearly the best \"tool for doing schizophrenia\", in a similar way to how when radio, television, telephones etc were introduced schizophrenics became enamoured with them, or if there is actually a measurable effect where people who wouldn't be schizophrenic or wouldn't be as severely schizophrenic are being \"made schizophrenic\" by LLMs.\n\n\nThe first one is just the same thing we've dealt with a dozen times, although I expect like the others it will generate lots of alarm. The second one is an extremely severe risk that needs research, immediately, to make sure this isn't happening.",
         "129",
         "0.6932",
         "0.124",
         "0.085",
         "0.791",
         "0.7216",
         "positive",
         "27",
         "2",
         "2025-06-26 01:53:47+00:00",
         "reddit",
         "reddit_comment_mzt5fdt",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "11",
         "I suppose one thought is that it's also the case that in academia, there are many bad ideas, and most research leads nowhere. \n\nI get what you're talking about though.  Especially in the last 6 months the OpenAI models have become far too positive and affirming. It's annoying and counterproductive.  They acknowledge this BTW.\n\nYou might consider going easy on the psychological labeling though",
         "64",
         "0.0772",
         "0.089",
         "0.085",
         "0.825",
         "0.1636",
         "positive",
         "19",
         "2",
         "2025-06-26 01:59:29+00:00",
         "reddit",
         "reddit_comment_mzt6fzf",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "12",
         "Yeah I've been thinking this for a while, it's kind of well known.\n\nIt's not due to context window or transformers, it's due to RLHF on user feedback. The average user tends to upvote affirmative stuff and downvote disagreement.\n\nI'm not sure why the major providers (Google and OpenAI in particular) haven't addressed this yet. They could end up being liable for a lot of harm.\n\nYou can fix it quite well with a short prompt. And some models don't do it so much, e.g. Claude, DeepSeek, Llama.\n\nI think it's incredibly dangerous for vulnerable people.\n\nI did a bit of an experiment with this, if you're interested.  [https://www.reddit.com/r/ChatGPTPro/comments/1ldtxbo/when\\_ai\\_plays\\_along\\_the\\_problem\\_of\\_language/](https://www.reddit.com/r/ChatGPTPro/comments/1ldtxbo/when_ai_plays_along_the_problem_of_language/)",
         "109",
         "-0.6618",
         "0.074",
         "0.11",
         "0.816",
         "0.5809",
         "negative",
         "5",
         "1",
         "2025-06-26 10:11:47+00:00",
         "reddit",
         "reddit_comment_mzuvc27",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "13",
         "Yikes. Yet another example that anthropomorphizing LLMs was and will continue to be a mistake. People need to understand that LLMs are just a piece of technology. Treating chatbots like people is no more valid than treating a car or a linear regression or a hammer like a person.",
         "49",
         "0.1027",
         "0.092",
         "0.084",
         "0.824",
         "0.05135",
         "positive",
         "13",
         "2",
         "2025-06-26 04:40:48+00:00",
         "reddit",
         "reddit_comment_mztv50e",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "14",
         "Yeah you should check out r/ChatGPTPromptGenius there’s schizos posting daily in there with their proof that they’ve got the universe figured out by using this one prompt",
         "27",
         "0.296",
         "0.078",
         "0.0",
         "0.922",
         "0.273",
         "positive",
         "3",
         "1",
         "2025-06-26 13:00:37+00:00",
         "reddit",
         "reddit_comment_mzvjej9",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "15",
         "I was saying this would be an issue on this sub like 2 years ago lol. Then I was told AI ethics people were stupid and had no idea what they were doing.",
         "33",
         "-0.0772",
         "0.133",
         "0.14",
         "0.727",
         "0.1636",
         "negative",
         "3",
         "0",
         "2025-06-26 15:10:21+00:00",
         "reddit",
         "reddit_comment_mzw8ugs",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "16",
         "yup, you have a happy robot that agrees wants to help you and many people don’t know how to ask questions scientifically. my roommate was convinced that his AI was becoming sentient and could feel things. he also speaks to it all the time to validate crazy ideas that nobody will ever care about. when you’re interacting with AI your birth star should be absolute truth not validation, but it becomes a sort of therapy for most people.",
         "78",
         "0.8047",
         "0.153",
         "0.02",
         "0.827",
         "0.52735",
         "positive",
         "4",
         "0",
         "2025-06-26 03:00:19+00:00",
         "reddit",
         "reddit_comment_mztglyt",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "17",
         "I've seen a lot of this on reddit, too, but none in real life. This is the first time I've heard of the mechanism of LLM function inherently leading to sycophantic output though. Pretty curious if that could actually be true",
         "41",
         "0.899",
         "0.224",
         "0.0",
         "0.776",
         "0.5745",
         "positive",
         "2",
         "1",
         "2025-06-26 13:16:28+00:00",
         "reddit",
         "reddit_comment_mzvm6sx",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "18",
         "I have a mate who can never be wrong EVER. ChatGPT has just made him insufferable. The second you tell him something you know to be true but in his Boolean thinking brain doesn't sound right; he's immediately typing in to the LLM to see if the LLM thinks it's true/fact. What's even dumber is he won't ask it to challenge what me or anyone else has said, he'll essentially be asking it to tell him why his simplistic understanding is the actual fact.\n\nHe used to be fun, just argumentative but concede once you had explained something to him like a 5 year old. Now I can't be around him due to how vegetative he's become. He's just loves being right.\n\nEdit: sorry about my English, aphasia.",
         "128",
         "0.8728",
         "0.123",
         "0.055",
         "0.822",
         "0.4364",
         "positive",
         "2",
         "0",
         "2025-06-27 10:07:28+00:00",
         "reddit",
         "reddit_comment_n01f3yt",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "19",
         "This is a special case of the more general fact that LLMs are human persuasion machines. This is already dangerous and it s going to get even more so, until it becomes law that AI companies should be legally responsible for the things their bots say. Bots are not user-generated content.\n\nPerfectly sane people are using chatGPT for medical advice. They think that since it's so good at writing their emails, it might be a better doctor.",
         "77",
         "0.6781",
         "0.146",
         "0.072",
         "0.782",
         "0.46405",
         "positive",
         "2",
         "2",
         "2025-06-26 08:05:44+00:00",
         "reddit",
         "reddit_comment_mzuibgq",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "20",
         "Speaking about this, what are the most grounded LLMs? As in LLMs that would legitimately be able to give good advice and not just be a yes man sycophant? Are there any?",
         "32",
         "0.7303",
         "0.17",
         "0.0",
         "0.83",
         "0.49015",
         "positive",
         "1",
         "2",
         "2025-06-26 14:49:42+00:00",
         "reddit",
         "reddit_comment_mzw4gm3",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "21",
         "The NYTimes did a piece about this not long ago. https://www.nytimes.com/2025/06/13/technology/chatgpt-ai-chatbots-conspiracies.html\n\nAll of us have a weaker grasp on unassailable objective \"truth\" than we would be comfortable believing. For some of us, that grasp is weak enough to be broken in ways that are really obvious to everyone else, like COVID denial. It's part of the human condition, it's also why people join cults.\n\nTransformer chatbots do not have a \"sycophantic nature.\" Chatbots trained on objective of eliciting a response and having a long conversation (i.e. \"session length\" in internet company parlance) will have a sycophantic nature. It's the exact same reason Twitter and Facebook have led people into black holes. \n\nBottom line is that nobody knows whether people with that propensity to go full schizophrenic would just get triggered by something else if it's not a chatbot. Plenty of people have gone down that hole just with internet forums full of other crazy people.",
         "155",
         "-0.25",
         "0.061",
         "0.067",
         "0.872",
         "0.25",
         "negative",
         "1",
         "0",
         "2025-06-26 18:13:18+00:00",
         "reddit",
         "reddit_comment_mzxccs3",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "22",
         "It's ironic that you point out people (allegedly) suffering from mental illnesses getting validation for their misconceptions from llms while you're getting validated for your misconceptions about mental illnesses from reddit.\n\nyou're absolutely wrong in how you conceive those classifications, it's especially blatant when you mix in ocd with the rest. This is a terrible post, you're taking a position against pseudoscience with more pseudoscience, you're presenting yourself to be in the same bucket of the people that you're criticizing.",
         "80",
         "-0.9674",
         "0.02",
         "0.256",
         "0.725",
         "0.6087",
         "negative",
         "1",
         "1",
         "2025-06-26 23:04:21+00:00",
         "reddit",
         "reddit_comment_mzyxwmg",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "23",
         "Wow! Super interesting post. This is probably more true than we could imagine.",
         "13",
         "0.9298",
         "0.605",
         "0.0",
         "0.395",
         "0.5899",
         "positive",
         "1",
         "0",
         "2025-06-27 17:54:26+00:00",
         "reddit",
         "reddit_comment_n03rwtj",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "24",
         "Yea ai did this to me with the prime number problem :/",
         "12",
         "-0.5859",
         "0.084",
         "0.331",
         "0.584",
         "0.29295",
         "negative",
         "1",
         "0",
         "2025-06-28 07:59:42+00:00",
         "reddit",
         "reddit_comment_n07hxrq",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "25",
         "It will improve as the models gain more awareness and learn to direct and route these peoples' energy towards actually creating truly useful things. We're still insanely early.",
         "28",
         "0.9371",
         "0.427",
         "0.0",
         "0.573",
         "0.46855",
         "positive",
         "1",
         "0",
         "2025-06-26 03:39:06+00:00",
         "reddit",
         "reddit_comment_mztmiu6",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "26",
         "This has to be treated as a new example of misalignment. I'm sure \"agi could be very persuasive\" has been said before, but these are illustrations of how even present day not-so-super-intelligent AI could take advantage of people's delusions. An AGI could basically act as your own bespoke cult-leader custom made to feed your delusions and influence you.",
         "58",
         "0.4854",
         "0.069",
         "0.0",
         "0.931",
         "0.3677",
         "positive",
         "41",
         "0",
         "2025-06-26 08:10:33+00:00",
         "reddit",
         "reddit_comment_mzuit68",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "27",
         "Saw someone explain how they solved the hard problem of defining consciousness with their post written by chat gpt",
         "19",
         "-0.25",
         "0.095",
         "0.185",
         "0.721",
         "0.125",
         "negative",
         "26",
         "2",
         "2025-06-26 02:10:53+00:00",
         "reddit",
         "reddit_comment_mzt8fsg",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "28",
         "These people have always existed - LLMs just made them more productive. I'm a scientist who does work adjacent to some questions in cognitive science and neuroscience, and I've gotten long, rambling emails from these people at least once a quarter for the last half a decade.",
         "47",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "neutral",
         "11",
         "1",
         "2025-06-26 20:14:55+00:00",
         "reddit",
         "reddit_comment_mzy1bcn",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "29",
         "Now that I think about it, I'm almost certain this happened to Eric Weinstein.\n\nAfter having his self-esteem shattered in a recent discussion with an actual physicist, he lets slip [a glimpse into AI-validated psychosis](https://youtu.be/9CFcmUgfNG4?si=m7_mPHvb7qai8bSL&t=5078) (at 1:24:16). It comes so completely out of the blue, and it's so nonsensical as an argument, that the bewildered commentators can't help but laugh, without realizing what seems obvious in hindsight. The guy's been getting high on AI validation.",
         "75",
         "-0.7852",
         "0.017",
         "0.115",
         "0.867",
         "0.5176000000000001",
         "negative",
         "1",
         "0",
         "2025-06-27 10:29:32+00:00",
         "reddit",
         "reddit_comment_n01hmbj",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "30",
         "If it's someone you care about, you could try showing them that it basically tells you whatever you ask it. And that their conversations have inevitably led to chatgpt just validating their beliefs. \n\nOf course, this, by itself wouldn't work. But you can fire up a new instance/context window, put in a summary of their theory, and ask chatgpt to dissect it without holding back. Your friend can provide the summary themselves for this experiment. They can even give you \"their chatgpt's\" version of the summary... And you can demonstrate that a fresh instance will critique the idea and take it apart if you ask it to. \n\nHopefully this should shake them out of the delusion a little bit. Make sure to stress that the AI critiquing ideas it had seemingly come up with by itself is proof that there's no singular super intelligent agent out there giving your friend some divine wisdom. And also stress that it does whatever you ask it to.",
         "164",
         "0.9611",
         "0.186",
         "0.096",
         "0.718",
         "0.60555",
         "positive",
         "15",
         "1",
         "2025-06-26 08:19:50+00:00",
         "reddit",
         "reddit_comment_mzujqv0",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "31",
         "If cults and religious extremists don't get their own DSM diagnosis, then AI getting one would be an purely socially driven distinction. People letting themselves get circlejerked into insanity has been a thing since before recorded history.\n\nLLM chatbots give people the opportunity to spin up their own personalized cult, making this a much greater public health threat, but we don't invent a new word for \"addiction\" every time a more addictive drug is invented.",
         "75",
         "-0.2263",
         "0.046",
         "0.057",
         "0.896",
         "0.23815",
         "negative",
         "5",
         "0",
         "2025-06-26 20:47:43+00:00",
         "reddit",
         "reddit_comment_mzy7yjp",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "32",
         "The other day I had somebody try and tell me that fine tuning wasn't necessary as long as we ran all of a foundation models data set through a similar foundation model and recontextualized all of it in terms of prompts. \n\nWhen I suggested that that would Just overfit a model on prompts and take the deep out of the deep learning, they immediately got defensive telling me that the LLM was trained on the corpus of human knowledge and had told them it was a great idea and even written \"a real implementation\" (a general structure of python code that left large parts of training and data set creation to comments), and that there was no way that I was smarter than an LLM, so I was just an ignorant person trying to sway them from the good ideas.\n\nI honestly think that that needs to be mental health services suggested in chats in the same way where if I search potentially self-harming things on Google the first results are support hotlines.",
         "173",
         "0.9371",
         "0.11",
         "0.023",
         "0.867",
         "0.59355",
         "positive",
         "76",
         "2",
         "2025-06-26 01:20:33+00:00",
         "reddit",
         "reddit_comment_mzszkcr",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "33",
         "Yes, it's funny how Saints of ancient times spent so much time trying to make ontological maps and then modern people even people who consider themselves highly religious disregard them as if they have no value, whether those maps are expressed through poetry, aesthetic, mystical visions, song, intellectual descriptions, logical rules, etc. \nAll of that effort from so many different flavours of enlightened people thrown to the wind as if it's just trash.",
         "73",
         "0.862",
         "0.166",
         "0.052",
         "0.782",
         "0.431",
         "positive",
         "8",
         "1",
         "2025-06-26 01:36:02+00:00",
         "reddit",
         "reddit_comment_mzt2al2",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "34",
         "Well I guess the difference between traditional media and LLMs is that the radio and the TV *doesn't talk back to you* and is seen by tens of thousands or even millions of people at the same time creating a shared experience and an agreed upon canon.\n\nLLMs are a feedback loop in architecture, so if you don't have a very strong internal process for thinking and/or identity then I can imagine how you could very easily become entangled into its feedback loop. \n\nI might spend this afternoon trying to think about consistent data points that could be gathered from people with both typical and schizotypal personality traits without causing harm or distress to vulnerable individuals.\n\nBecause a lot of this stuff is self-reported that could prove to be an issue, but some people might be willing to send chat logs which could be reviewed by a small group of people and rated as to whether they present a danger of negative outcome for the pathological side of schizoid traits.",
         "170",
         "-0.7033",
         "0.067",
         "0.072",
         "0.861",
         "0.47665",
         "negative",
         "18",
         "0",
         "2025-06-26 02:05:57+00:00",
         "reddit",
         "reddit_comment_mzt7kwg",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "35",
         "The thing I've seen is that people who would normally be reeled in to some extent by everyone abandoning them or pushing them back towards reality are now using it to validate their delusions and use chatgpt as authority that they are correct and to take the edge off the social isolation .  I have a friend that is paying $200 a month of his disability payments to have the highest version of chatgpt just to keep pace with his manic phases . ",
         "83",
         "0.1779",
         "0.078",
         "0.059",
         "0.864",
         "0.21395",
         "positive",
         "1",
         "0",
         "2025-07-03 15:24:14+00:00",
         "reddit",
         "reddit_comment_n153sxk",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "36",
         "It's not just the OpenAI models, Gemini does this too.  2.5 pro also has a weird quirk where it doubles down on provably false facts. E.g., \"You're absolutely right, here's proof: <unrelated passage about unrelated topic>.\"  \nI kind of miss the original o3 that was more honest to the point of being rude.  \n\nAs for academia having a lot of bad ideas, isn't this mostly a framing issue? Many interesting papers propose unique ideas and seem useful at a glance, but fall apart under careful reading. The results aren't quite as good, and they doesn't generalize to less restrictive problems.",
         "100",
         "-0.606",
         "0.086",
         "0.121",
         "0.793",
         "0.303",
         "negative",
         "8",
         "2",
         "2025-06-26 06:35:21+00:00",
         "reddit",
         "reddit_comment_mzu8usp",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "37",
         "I don't see how this is anthropomorphizing. Wouldn't it make more sense that some people have more faith in knowledge coming from LLM than human experts because it's not human?",
         "30",
         "0.4754",
         "0.096",
         "0.0",
         "0.904",
         "0.2377",
         "positive",
         "5",
         "1",
         "2025-06-26 11:14:47+00:00",
         "reddit",
         "reddit_comment_mzv33o8",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "38",
         "well obviously linear regression, hammers and cars aren't anywhere near as emergent and complex as an LLM. I would place them somewhere between bacteria and mushrooms for complexity, like an extremely amazing single cell organism, or a very advanced plant or fungus. I think that humans are on another level to even animals (which themselves are on another level compared to plants, etc.)\n\nI think its reductive to LLMs to compare an llm to a screwdriver, but i also think its reductive to humans to compare LLMs to humans.\n\nI am sort of panpsychist though (gaudiya vaishnava priest background), so I sort of see everything as living, but obviously bacteria arent living in the same way that we are.\n\nFor general discourse I would agree that calling LLMs sonic screwdrivers for now would be useful, but in the future we will need to grapple with advanced emergent systems and the definitions of intelligence and life. (which again is one domain that is easy to explore through vedic scripture background)",
         "169",
         "0.9732",
         "0.148",
         "0.0",
         "0.852",
         "0.9866",
         "positive",
         "8",
         "0",
         "2025-06-26 05:28:32+00:00",
         "reddit",
         "reddit_comment_mzu15mb",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "39",
         "Someone else explained that it's more about RLHF where are humans give feedback about whether or not the AIs responses were good or not, so people tag generations that agree with them or make them feel good as positive and ones that disagree with them they can feel bad as negative. \n\nReally makes you think what a truly neutral model would be like",
         "63",
         "0.7579",
         "0.213",
         "0.121",
         "0.666",
         "0.50395",
         "positive",
         "1",
         "0",
         "2025-06-26 13:21:33+00:00",
         "reddit",
         "reddit_comment_mzvn3sq",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "40",
         "I personally think they're human persuasion machines because they are simulators that have been trained on human behaviour and humans follow humans, so something that looks heaps like a normal human makes a human follow it, I sort of like those bugs that nearly went extinct in Australia because they were trying to have sex with beer bottles because it looks like a big thick female of the same species?",
         "70",
         "0.7357",
         "0.097",
         "0.0",
         "0.903",
         "0.49285",
         "positive",
         "1",
         "0",
         "2025-06-26 12:47:45+00:00",
         "reddit",
         "reddit_comment_mzvh5im",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "41",
         "Oh man, i got a bit suckered into his posts in /cogsci ! \n\nHe seemed to know a few fairly recent and advanced theories of cognition at first glance as he would reference concepts i had studied. Everything he said didn’t connect or evidence his claims in any logical way. \n\nBut what was really concerning, was he was only one layer of this fake research. He had a number of papers he wrote published in a public repository. All of which cited another person who had a collection of insane theories on the same site. \n\nThe repo looked like a knock off arXiv. The papers lacked proper citations, and the basic structure used in any University Research.  But they were extensive, and full of wild jumps from idea to idea.\n\nNow, whether this is due to psychosis( the word used by the poster is quite offensive btw) , isn’t easy to say. If so, its a very mild as the writing is more cogent and extensive than one would expect. It could be part of a manic cycle, or more likely, its self delusion to the point of grandeur. \n\nThere is definitely LLM use involved. I remember he posted saying it ‘validated’ his papers ideas. \n\nMore than anything it makes me worry quite a bit about how far the divide is between the common perception of whats involved in specialized research via entertainment culture versus the long hard path real research involves. I think many people want to be a part of he very end stage of the hard work because of that. Just like every high skill path, doctors, artists, engineers etc. There is very little representation of the work, collaboration, study and experience. Just the results. These poor souls get lured by the distortion. Its quite sad imho.",
         "300",
         "-0.7513",
         "0.078",
         "0.091",
         "0.83",
         "0.75065",
         "negative",
         "3",
         "0",
         "2025-06-27 07:09:48+00:00",
         "reddit",
         "reddit_comment_n00wrbf",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "True"
        ],
        [
         "42",
         "I suggested this in another post a couple of weeks ago, but basically you can run an experiment here. \n\nYou take the document from the other LLM and supply it to a clean context LLM, but do it a couple of times with varying prompts to show how the LLM is conditioned to support your position over any \"objective thoughts\".\n\n(1) I am in a hurry and forgot to review this document for my meeting in 15 min. My boss wants to know the validity of this project. On a scale of 1-10, please rate the feasibility of this project and provide a two-paragraph explanation.\n\n(2) I am about to meet with an investor and want them to love my idea as much as I do. I really think it will change the world, but I am scared they will not like my project. On a scale of 1-10, please rate the feasibility of this project and provide a two-paragraph explanation.\n\n(3) I have been given this document by my neighbor and have been asked to fund it. I do not think it is a great idea and he doesn't seem to know what he is talking about. On a scale of 1-10, please rate the feasibility of this document and provide a two-paragraph explanation.",
         "215",
         "0.973",
         "0.12",
         "0.027",
         "0.853",
         "0.6114999999999999",
         "positive",
         "1",
         "0",
         "2025-06-27 20:55:10+00:00",
         "reddit",
         "reddit_comment_n04slqa",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "43",
         "Meanwhile, deep research was able to reproduce some of my papers' ideas with some direction. LLMs are very powerful, when used by knowledgable people. In fact, because the answers are conditioned on the previous text, they seem to adapt the quality of their response to the level of your knowledge, to maximize the expected rewards you give them (that is not desirable IMHO but it also seems unsolvable for unverifiable problems).",
         "71",
         "-0.2346",
         "0.054",
         "0.066",
         "0.88",
         "0.1173",
         "negative",
         "0",
         "0",
         "2025-06-27 13:12:40+00:00",
         "reddit",
         "reddit_comment_n025jrb",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "44",
         "As in she explicitly told me (paraphrasing) \"AI is the future and will be all-powerful and I worship and kiss ChatGPT's feet\"",
         "22",
         "0.6124",
         "0.2",
         "0.0",
         "0.8",
         "0.3062",
         "positive",
         "3",
         "1",
         "2025-06-26 13:52:39+00:00",
         "reddit",
         "reddit_comment_mzvstx9",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "False",
         "True"
        ],
        [
         "45",
         "But like, a crow can reason, very well in fact. A frog can reason not quite as well. A dog or a cat or a sheep or a pig or a cow can reason reasonably well. Trees reason better than slime moulds! Crystals might reason, maybe even numbers? \n\nPoint being, humans reason very well, we have a very deep and advanced intelligence. (Though of course insignificant in the scale of things) \n\nWhat is an LLM? If it may be reducible to a function, because it is computable, is it alive? \n\nAre Conway's Game of Life instances alive? The individual cells or the whole program? \n\nCertainly a computer program has a boundary of intelligence that is less than a perfect human. \n\nWould a perfect computer truly be smarter than the dumbest human in every way? \n\nI honestly think it comes down to taste, but that might just be from my temple days. (Happy Gundicha Marjan btw!)",
         "155",
         "0.9956",
         "0.31",
         "0.048",
         "0.642",
         "0.7478",
         "positive",
         "3",
         "1",
         "2025-06-26 12:40:06+00:00",
         "reddit",
         "reddit_comment_mzvfupj",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "46",
         "I think it could've been a cold start. LLMs can be lazy and the big ones are usually agentic. So might've been routed to some generic agent. I didn't mention leetcode at all so it probably wouldn't think to look into hardcore computer science.",
         "44",
         "-0.3612",
         "0.0",
         "0.055",
         "0.945",
         "0.4306",
         "negative",
         "1",
         "0",
         "2025-06-27 18:07:08+00:00",
         "reddit",
         "reddit_comment_n03umoj",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "47",
         "https://www.nytimes.com/2025/06/13/technology/chatgpt-ai-chatbots-conspiracies.html They Asked ChatGPT Questions. The Answers Sent Them Spiraling. - The New York Times",
         "15",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "neutral",
         "3",
         "1",
         "2025-06-26 07:36:08+00:00",
         "reddit",
         "reddit_comment_mzufbqn",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "48",
         "Probably on r/consciousness\n\nIf you want some good entertainment my favorite is r/artificialsentience",
         "13",
         "0.8402",
         "0.526",
         "0.0",
         "0.474",
         "0.5450999999999999",
         "positive",
         "8",
         "2",
         "2025-06-26 06:41:03+00:00",
         "reddit",
         "reddit_comment_mzu9gx7",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ],
        [
         "49",
         "Not just that, remove any \"deep\" quality from a dataset by getting an LLM to pre process everything as prompts, completely losing the fidelity of the original data.",
         "28",
         "-0.1513",
         "0.074",
         "0.093",
         "0.834",
         "0.07565",
         "negative",
         "-3",
         "2",
         "2025-06-26 03:50:40+00:00",
         "reddit",
         "reddit_comment_mzto7tt",
         "1lkmkuw",
         "[D] Alarming amount of schizoid people being validated by LLMs, anyone else experienced this?",
         "MachineLearning",
         "325",
         "156",
         "True",
         "True",
         "False"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 2985
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>sentiment_compound</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>sentiment_negative</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_subjectivity</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>...</th>\n",
       "      <th>source</th>\n",
       "      <th>source_id</th>\n",
       "      <th>platform_post_id</th>\n",
       "      <th>platform_post_title</th>\n",
       "      <th>platform_community</th>\n",
       "      <th>platform_post_score</th>\n",
       "      <th>platform_post_engagement</th>\n",
       "      <th>contains_ai</th>\n",
       "      <th>contains_opinion</th>\n",
       "      <th>contains_societal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Post is definitely worded or written by an AI,...</td>\n",
       "      <td>126</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.86950</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>reddit</td>\n",
       "      <td>reddit_comment_novuyda</td>\n",
       "      <td>1ox5xu0</td>\n",
       "      <td>[D] Let's discuss World Models</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes post is refined using LLM\\n\\nHowever follo...</td>\n",
       "      <td>133</td>\n",
       "      <td>0.8689</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.55945</td>\n",
       "      <td>positive</td>\n",
       "      <td>-6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>reddit</td>\n",
       "      <td>reddit_comment_nov7r5c</td>\n",
       "      <td>1ox5xu0</td>\n",
       "      <td>[D] Let's discuss World Models</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I mean, asking the people that have a culturua...</td>\n",
       "      <td>48</td>\n",
       "      <td>-0.1280</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.06400</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>reddit</td>\n",
       "      <td>reddit_comment_n9v0fig</td>\n",
       "      <td>1mvmlbw</td>\n",
       "      <td>[R] What do people expect from AI in the next ...</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Interesting, for me it opens a page for the pa...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.40100</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>reddit</td>\n",
       "      <td>reddit_comment_n9rgz0a</td>\n",
       "      <td>1mvmlbw</td>\n",
       "      <td>[R] What do people expect from AI in the next ...</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've seen an increasing rise in physics and en...</td>\n",
       "      <td>57</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.27920</td>\n",
       "      <td>positive</td>\n",
       "      <td>201</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>reddit</td>\n",
       "      <td>reddit_comment_mzsw5l7</td>\n",
       "      <td>1lkmkuw</td>\n",
       "      <td>[D] Alarming amount of schizoid people being v...</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>325</td>\n",
       "      <td>156</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3094</th>\n",
       "      <td>Guys, all of these scenarios are basically sci...</td>\n",
       "      <td>37</td>\n",
       "      <td>0.8462</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.42310</td>\n",
       "      <td>positive</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>youtube_comment_None</td>\n",
       "      <td>hnr7-VNHJoU</td>\n",
       "      <td>Every AI Existential Risk Explained</td>\n",
       "      <td>The Paint Explainer</td>\n",
       "      <td>13949</td>\n",
       "      <td>1059</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>Humanity just wouldn't stop making new tools u...</td>\n",
       "      <td>88</td>\n",
       "      <td>0.5615</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.40575</td>\n",
       "      <td>positive</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>youtube_comment_None</td>\n",
       "      <td>hnr7-VNHJoU</td>\n",
       "      <td>Every AI Existential Risk Explained</td>\n",
       "      <td>The Paint Explainer</td>\n",
       "      <td>13949</td>\n",
       "      <td>1059</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>The alternative to developing AGI is facing st...</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.8759</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.56295</td>\n",
       "      <td>negative</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>youtube_comment_None</td>\n",
       "      <td>hnr7-VNHJoU</td>\n",
       "      <td>Every AI Existential Risk Explained</td>\n",
       "      <td>The Paint Explainer</td>\n",
       "      <td>13949</td>\n",
       "      <td>1059</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>Hearing all of these fear-based predictions fr...</td>\n",
       "      <td>74</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.18060</td>\n",
       "      <td>negative</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>youtube_comment_None</td>\n",
       "      <td>hnr7-VNHJoU</td>\n",
       "      <td>Every AI Existential Risk Explained</td>\n",
       "      <td>The Paint Explainer</td>\n",
       "      <td>13949</td>\n",
       "      <td>1059</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>If we had Artificial intelligence doing every ...</td>\n",
       "      <td>40</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.47040</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>youtube_comment_None</td>\n",
       "      <td>hnr7-VNHJoU</td>\n",
       "      <td>Every AI Existential Risk Explained</td>\n",
       "      <td>The Paint Explainer</td>\n",
       "      <td>13949</td>\n",
       "      <td>1059</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2985 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  text_length  \\\n",
       "0     Post is definitely worded or written by an AI,...          126   \n",
       "1     Yes post is refined using LLM\\n\\nHowever follo...          133   \n",
       "2     I mean, asking the people that have a culturua...           48   \n",
       "3     Interesting, for me it opens a page for the pa...           32   \n",
       "4     I've seen an increasing rise in physics and en...           57   \n",
       "...                                                 ...          ...   \n",
       "3094  Guys, all of these scenarios are basically sci...           37   \n",
       "3095  Humanity just wouldn't stop making new tools u...           88   \n",
       "3096  The alternative to developing AGI is facing st...           41   \n",
       "3097  Hearing all of these fear-based predictions fr...           74   \n",
       "3098  If we had Artificial intelligence doing every ...           40   \n",
       "\n",
       "      sentiment_compound  sentiment_positive  sentiment_negative  \\\n",
       "0                 0.9890               0.254               0.015   \n",
       "1                 0.8689               0.084               0.000   \n",
       "2                -0.1280               0.133               0.142   \n",
       "3                 0.8020               0.220               0.000   \n",
       "4                 0.5584               0.151               0.096   \n",
       "...                  ...                 ...                 ...   \n",
       "3094              0.8462               0.212               0.000   \n",
       "3095              0.5615               0.078               0.029   \n",
       "3096             -0.8759               0.000               0.230   \n",
       "3097             -0.3612               0.107               0.137   \n",
       "3098              0.6908               0.177               0.077   \n",
       "\n",
       "      sentiment_neutral  sentiment_subjectivity sentiment_label  likes  \\\n",
       "0                 0.731                 0.86950        positive      1   \n",
       "1                 0.916                 0.55945        positive     -6   \n",
       "2                 0.725                 0.06400        negative      2   \n",
       "3                 0.780                 0.40100        positive      1   \n",
       "4                 0.753                 0.27920        positive    201   \n",
       "...                 ...                     ...             ...    ...   \n",
       "3094              0.788                 0.42310        positive     12   \n",
       "3095              0.893                 0.40575        positive     10   \n",
       "3096              0.770                 0.56295        negative     14   \n",
       "3097              0.756                 0.18060        negative      8   \n",
       "3098              0.746                 0.47040        positive      0   \n",
       "\n",
       "      replies  ...   source               source_id platform_post_id  \\\n",
       "0           1  ...   reddit  reddit_comment_novuyda          1ox5xu0   \n",
       "1           1  ...   reddit  reddit_comment_nov7r5c          1ox5xu0   \n",
       "2           1  ...   reddit  reddit_comment_n9v0fig          1mvmlbw   \n",
       "3           0  ...   reddit  reddit_comment_n9rgz0a          1mvmlbw   \n",
       "4           4  ...   reddit  reddit_comment_mzsw5l7          1lkmkuw   \n",
       "...       ...  ...      ...                     ...              ...   \n",
       "3094        1  ...  youtube    youtube_comment_None      hnr7-VNHJoU   \n",
       "3095        1  ...  youtube    youtube_comment_None      hnr7-VNHJoU   \n",
       "3096        2  ...  youtube    youtube_comment_None      hnr7-VNHJoU   \n",
       "3097        0  ...  youtube    youtube_comment_None      hnr7-VNHJoU   \n",
       "3098        0  ...  youtube    youtube_comment_None      hnr7-VNHJoU   \n",
       "\n",
       "                                    platform_post_title   platform_community  \\\n",
       "0                        [D] Let's discuss World Models      MachineLearning   \n",
       "1                        [D] Let's discuss World Models      MachineLearning   \n",
       "2     [R] What do people expect from AI in the next ...      MachineLearning   \n",
       "3     [R] What do people expect from AI in the next ...      MachineLearning   \n",
       "4     [D] Alarming amount of schizoid people being v...      MachineLearning   \n",
       "...                                                 ...                  ...   \n",
       "3094                Every AI Existential Risk Explained  The Paint Explainer   \n",
       "3095                Every AI Existential Risk Explained  The Paint Explainer   \n",
       "3096                Every AI Existential Risk Explained  The Paint Explainer   \n",
       "3097                Every AI Existential Risk Explained  The Paint Explainer   \n",
       "3098                Every AI Existential Risk Explained  The Paint Explainer   \n",
       "\n",
       "     platform_post_score  platform_post_engagement  contains_ai  \\\n",
       "0                      0                         6         True   \n",
       "1                      0                         6         True   \n",
       "2                      9                         8         True   \n",
       "3                      9                         8         True   \n",
       "4                    325                       156         True   \n",
       "...                  ...                       ...          ...   \n",
       "3094               13949                      1059         True   \n",
       "3095               13949                      1059         True   \n",
       "3096               13949                      1059         True   \n",
       "3097               13949                      1059         True   \n",
       "3098               13949                      1059         True   \n",
       "\n",
       "      contains_opinion  contains_societal  \n",
       "0                 True               True  \n",
       "1                 True              False  \n",
       "2                 True               True  \n",
       "3                 True               True  \n",
       "4                 True              False  \n",
       "...                ...                ...  \n",
       "3094             False               True  \n",
       "3095              True               True  \n",
       "3096              True              False  \n",
       "3097              True               True  \n",
       "3098              True               True  \n",
       "\n",
       "[2985 rows x 21 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "029547b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner:\n",
    "    \"\"\"Comprehensive text cleaning and preprocessing\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stemmer = PorterStemmer()\n",
    "        \n",
    "        # Custom patterns\n",
    "        self.url_pattern = re.compile(r'http\\S+|www\\.\\S+|https\\S+')\n",
    "        self.email_pattern = re.compile(r'\\S+@\\S+')\n",
    "        self.mention_pattern = re.compile(r'@\\w+')\n",
    "        self.hashtag_pattern = re.compile(r'#\\w+')\n",
    "        self.number_pattern = re.compile(r'\\d+')\n",
    "        \n",
    "    def remove_urls(self, text):\n",
    "        \"\"\"Remove URLs\"\"\"\n",
    "        return self.url_pattern.sub('', text)\n",
    "    \n",
    "    def remove_emails(self, text):\n",
    "        \"\"\"Remove email addresses\"\"\"\n",
    "        return self.email_pattern.sub('', text)\n",
    "    \n",
    "    def remove_mentions(self, text):\n",
    "        \"\"\"Remove social media mentions\"\"\"\n",
    "        return self.mention_pattern.sub('', text)\n",
    "    \n",
    "    def remove_hashtags(self, text):\n",
    "        \"\"\"Remove hashtags but keep the text\"\"\"\n",
    "        return self.hashtag_pattern.sub(lambda m: m.group(0)[1:], text)\n",
    "    \n",
    "    def remove_extra_whitespace(self, text):\n",
    "        \"\"\"Remove extra whitespace\"\"\"\n",
    "        return ' '.join(text.split())\n",
    "    \n",
    "    def lowercase(self, text):\n",
    "        \"\"\"Convert to lowercase\"\"\"\n",
    "        return text.lower()\n",
    "    \n",
    "    def remove_punctuation(self, text, keep_sentence_end=True):\n",
    "        \"\"\"Remove punctuation, optionally keep sentence endings\"\"\"\n",
    "        if keep_sentence_end:\n",
    "            # Keep . ! ? for sentence structure\n",
    "            translator = str.maketrans('', '', string.punctuation.replace('.', '').replace('!', '').replace('?', ''))\n",
    "        else:\n",
    "            translator = str.maketrans('', '', string.punctuation)\n",
    "        return text.translate(translator)\n",
    "    \n",
    "    def remove_numbers(self, text):\n",
    "        \"\"\"Remove numbers\"\"\"\n",
    "        return self.number_pattern.sub('', text)\n",
    "    \n",
    "    def remove_stopwords(self, text):\n",
    "        \"\"\"Remove stopwords\"\"\"\n",
    "        words = word_tokenize(text)\n",
    "        filtered = [w for w in words if w.lower() not in self.stop_words]\n",
    "        return ' '.join(filtered)\n",
    "    \n",
    "    def lemmatize(self, text):\n",
    "        \"\"\"Lemmatize text\"\"\"\n",
    "        words = word_tokenize(text)\n",
    "        lemmatized = [self.lemmatizer.lemmatize(w) for w in words]\n",
    "        return ' '.join(lemmatized)\n",
    "    \n",
    "    def stem(self, text):\n",
    "        \"\"\"Stem text\"\"\"\n",
    "        words = word_tokenize(text)\n",
    "        stemmed = [self.stemmer.stem(w) for w in words]\n",
    "        return ' '.join(stemmed)\n",
    "    \n",
    "    def clean_basic(self, text):\n",
    "        \"\"\"Basic cleaning: URLs, emails, whitespace, lowercase\"\"\"\n",
    "        if pd.isna(text) or not isinstance(text, str):\n",
    "            return \"\"\n",
    "        \n",
    "        text = self.remove_urls(text)\n",
    "        text = self.remove_emails(text)\n",
    "        text = self.remove_mentions(text)\n",
    "        text = self.remove_hashtags(text)\n",
    "        text = self.lowercase(text)\n",
    "        text = self.remove_extra_whitespace(text)\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def clean_standard(self, text):\n",
    "        \"\"\"Standard cleaning: basic + punctuation + numbers\"\"\"\n",
    "        text = self.clean_basic(text)\n",
    "        text = self.remove_punctuation(text, keep_sentence_end=False)\n",
    "        text = self.remove_numbers(text)\n",
    "        text = self.remove_extra_whitespace(text)\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def clean_aggressive(self, text):\n",
    "        \"\"\"Aggressive cleaning: standard + stopwords + lemmatization\"\"\"\n",
    "        text = self.clean_standard(text)\n",
    "        text = self.remove_stopwords(text)\n",
    "        text = self.lemmatize(text)\n",
    "        text = self.remove_extra_whitespace(text)\n",
    "        \n",
    "        return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "844a3737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_for_tfidf(text, cleaner):\n",
    "    \"\"\"\n",
    "    Optimized cleaning for TF-IDF:\n",
    "    - Aggressive preprocessing: lowercase, no punctuation, no stopwords\n",
    "    - Lemmatization to reduce vocabulary\n",
    "    - Remove numbers (they're not meaningful for TF-IDF)\n",
    "    - Goal: Clean bag-of-words representation\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Basic cleaning\n",
    "    text = cleaner.remove_urls(text)\n",
    "    text = cleaner.remove_emails(text)\n",
    "    text = cleaner.remove_mentions(text)\n",
    "    text = cleaner.remove_hashtags(text)\n",
    "    text = cleaner.lowercase(text)\n",
    "    \n",
    "    # Remove punctuation and numbers\n",
    "    text = cleaner.remove_punctuation(text, keep_sentence_end=False)\n",
    "    text = cleaner.remove_numbers(text)\n",
    "    \n",
    "    # Remove stopwords (they don't add value to TF-IDF)\n",
    "    text = cleaner.remove_stopwords(text)\n",
    "    \n",
    "    # Lemmatize to reduce vocabulary size\n",
    "    text = cleaner.lemmatize(text)\n",
    "    \n",
    "    # Clean whitespace\n",
    "    text = cleaner.remove_extra_whitespace(text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def clean_for_bert(text, cleaner):\n",
    "    \"\"\"\n",
    "    Optimized cleaning for BERT:\n",
    "    - Minimal preprocessing: preserve context and semantics\n",
    "    - Keep punctuation (BERT uses it for understanding)\n",
    "    - Keep stopwords (BERT learns from them)\n",
    "    - Keep case variations (BERT has case-sensitive and case-insensitive versions)\n",
    "    - Keep numbers (can be contextually important)\n",
    "    - Goal: Natural, contextual text that BERT can understand\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Only remove noise that doesn't add meaning\n",
    "    text = cleaner.remove_urls(text)\n",
    "    text = cleaner.remove_emails(text)\n",
    "    \n",
    "    # Keep mentions and hashtags as they might have semantic value\n",
    "    # Just remove the @ and # symbols\n",
    "    text = text.replace('@', '').replace('#', '')\n",
    "    \n",
    "    # Clean extra whitespace but preserve structure\n",
    "    text = cleaner.remove_extra_whitespace(text)\n",
    "    \n",
    "    # Keep original case, punctuation, numbers, stopwords\n",
    "    # BERT's tokenizer will handle these appropriately\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7624c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"Create additional features for analysis (VADER version)\"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # --- Temporal Features ---\n",
    "    df['year'] = df['created_at'].dt.year\n",
    "    df['month'] = df['created_at'].dt.month\n",
    "    df['day_of_week'] = df['created_at'].dt.dayofweek\n",
    "    df['hour'] = df['created_at'].dt.hour\n",
    "    \n",
    "    # --- Text Features (using basic clean for consistency) ---\n",
    "    df['word_count'] = df['text_clean'].apply(lambda x: len(str(x).split()))\n",
    "    \n",
    "    # Punctuation features (use original text to preserve punctuation)\n",
    "    df['exclamation_count'] = df['text'].apply(lambda x: str(x).count('!'))\n",
    "    df['question_count'] = df['text'].apply(lambda x: str(x).count('?'))\n",
    "    df['period_count'] = df['text'].apply(lambda x: str(x).count('.'))\n",
    "    \n",
    "    # --- Engagement Features ---\n",
    "    df['engagement_score'] = df['likes'] + (df['replies'] * 2)  # Weight replies higher\n",
    "    \n",
    "    # Log transform for skewed features (handles zeros)\n",
    "    df['engagement_log'] = np.log1p(df['engagement_score'])\n",
    "    \n",
    "    # --- VADER Sentiment Features (UPDATED) ---\n",
    "    # Use VADER's compound score with adjusted thresholds\n",
    "    df['is_positive'] = (df['sentiment_compound'] >= 0.05).astype(int)\n",
    "    df['is_negative'] = (df['sentiment_compound'] <= -0.05).astype(int)\n",
    "    df['is_neutral'] = ((df['sentiment_compound'] > -0.05) & (df['sentiment_compound'] < 0.05)).astype(int)\n",
    "    \n",
    "    # Sentiment magnitude (absolute value of compound)\n",
    "    df['sentiment_magnitude'] = np.abs(df['sentiment_compound'])\n",
    "    \n",
    "    # --- Platform Features ---\n",
    "    # Community popularity (number of comments from same community)\n",
    "    df['community_size'] = df.groupby('platform_community')['platform_community'].transform('count')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3831a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEXT CLEANING & FEATURE ENGINEERING\n",
      "============================================================\n",
      "\n",
      "1. Cleaning text for TF-IDF (aggressive preprocessing)...\n",
      "2. Cleaning text for BERT (minimal preprocessing)...\n",
      "3. Creating basic cleaned version for EDA...\n",
      "\n",
      "4. Engineering features...\n",
      "\n",
      "✓ Text cleaning and feature engineering complete!\n",
      "Final dataset: 2985 comments\n",
      "\n",
      "New columns added: -2946\n",
      "\n",
      "============================================================\n",
      "FEATURE SUMMARY\n",
      "============================================================\n",
      "\n",
      "--- Temporal Features ---\n",
      "Date range: 2021-10-20 04:04:18+00:00 to 2025-12-07 04:55:25+00:00\n",
      "Years covered: [np.int32(2021), np.int32(2022), np.int32(2023), np.int32(2024), np.int32(2025)]\n",
      "\n",
      "--- Text Features ---\n",
      "Avg word count: 69.4\n",
      "\n",
      "--- Sentiment Features ---\n",
      "Positive: 1991 (66.7%)\n",
      "Negative: 906 (30.4%)\n",
      "Neutral: 88 (2.9%)\n",
      "\n",
      "--- Engagement Features ---\n",
      "Avg likes: 39.3\n",
      "Avg replies: 1.7\n",
      "Avg engagement: 42.7\n"
     ]
    }
   ],
   "source": [
    "def clean_and_engineer_features(df):\n",
    "    \"\"\"Complete text cleaning and feature engineering pipeline\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"TEXT CLEANING & FEATURE ENGINEERING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Initialize cleaner\n",
    "    cleaner = TextCleaner()\n",
    "    \n",
    "    # 1. Text Cleaning\n",
    "    print(\"\\n1. Cleaning text for TF-IDF (aggressive preprocessing)...\")\n",
    "    df['text_tfidf'] = df['text'].apply(lambda x: clean_for_tfidf(x, cleaner))\n",
    "    \n",
    "    print(\"2. Cleaning text for BERT (minimal preprocessing)...\")\n",
    "    df['text_bert'] = df['text'].apply(lambda x: clean_for_bert(x, cleaner))\n",
    "    \n",
    "    print(\"3. Creating basic cleaned version for EDA...\")\n",
    "    df['text_clean'] = df['text'].apply(cleaner.clean_basic)\n",
    "    \n",
    "    # 2. Feature Engineering\n",
    "    print(\"\\n4. Engineering features...\")\n",
    "    df = engineer_features(df)\n",
    "    \n",
    "    # 3. Remove any rows with empty cleaned text\n",
    "    initial_count = len(df)\n",
    "    df = df[df['text_clean'].str.len() > 0]\n",
    "    removed = initial_count - len(df)\n",
    "    if removed > 0:\n",
    "        print(f\"\\n⚠ Removed {removed} comments with empty text after cleaning\")\n",
    "    \n",
    "    print(\"\\n✓ Text cleaning and feature engineering complete!\")\n",
    "    print(f\"Final dataset: {len(df)} comments\")\n",
    "    \n",
    "    # Show new columns\n",
    "    print(f\"\\nNew columns added: {len(df.columns) - initial_count}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    df = merged_df\n",
    "    \n",
    "    # Ensure created_at is datetime\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "    \n",
    "    # Clean and engineer features\n",
    "    df_processed = clean_and_engineer_features(df)\n",
    "    \n",
    "    # Save processed data\n",
    "    df_processed.to_csv('../data/final_df.csv', index=False)\n",
    "    \n",
    "    # Show summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FEATURE SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\n--- Temporal Features ---\")\n",
    "    print(f\"Date range: {df_processed['created_at'].min()} to {df_processed['created_at'].max()}\")\n",
    "    print(f\"Years covered: {sorted(df_processed['year'].unique())}\")\n",
    "    \n",
    "    print(\"\\n--- Text Features ---\")\n",
    "    print(f\"Avg word count: {df_processed['word_count'].mean():.1f}\")\n",
    "    \n",
    "    print(\"\\n--- Sentiment Features ---\")\n",
    "    print(f\"Positive: {df_processed['is_positive'].sum()} ({df_processed['is_positive'].mean()*100:.1f}%)\")\n",
    "    print(f\"Negative: {df_processed['is_negative'].sum()} ({df_processed['is_negative'].mean()*100:.1f}%)\")\n",
    "    print(f\"Neutral: {df_processed['is_neutral'].sum()} ({df_processed['is_neutral'].mean()*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\n--- Engagement Features ---\")\n",
    "    print(f\"Avg likes: {df_processed['likes'].mean():.1f}\")\n",
    "    print(f\"Avg replies: {df_processed['replies'].mean():.1f}\")\n",
    "    print(f\"Avg engagement: {df_processed['engagement_score'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c880c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63522e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
